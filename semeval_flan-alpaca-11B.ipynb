{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b37c7bb-c037-4504-a2e2-4010b3726ac8",
   "metadata": {},
   "source": [
    "# Stance Classification for SemEval2016\n",
    "- read in the data and pre-process\n",
    "- set up an LLM\n",
    "- Investigate different prompting schemes\n",
    "    - just context\n",
    "    - context + few-shot learning\n",
    "    - content + few-shot learning + reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b436af4-75ff-4598-a9e3-70e746e1f99d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.33.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.17.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.8.8)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.30.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: langchain in /home/jovyan/.local/lib/python3.10/site-packages (0.0.158)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.13)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.4)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.2)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /home/jovyan/.local/lib/python3.10/site-packages (from langchain) (0.5.7)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.4)\n",
      "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
      "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /home/jovyan/.local/lib/python3.10/site-packages (from langchain) (1.2.4)\n",
      "Requirement already satisfied: pydantic<2,>=1 in /home/jovyan/.local/lib/python3.10/site-packages (from langchain) (1.10.8)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.30.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/jovyan/.local/lib/python3.10/site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: tqdm>=4.48.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.65.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /home/jovyan/.local/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.19.0)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /home/jovyan/.local/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (1.5.1)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in /home/jovyan/.local/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.8.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1->langchain) (4.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.5.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.3->langchain) (2.0.2)\n",
      "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.22.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1+cu118)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.0.0)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (3.25.0)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (15.0.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.6.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Collecting deepspeed\n",
      "  Downloading deepspeed-0.10.2.tar.gz (858 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m858.2/858.2 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting hjson (from deepspeed)\n",
      "  Using cached hjson-3.1.0-py3-none-any.whl (54 kB)\n",
      "Collecting ninja (from deepspeed)\n",
      "  Using cached ninja-1.11.1-py2.py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (145 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deepspeed) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from deepspeed) (23.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from deepspeed) (5.9.5)\n",
      "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from deepspeed) (9.0.0)\n",
      "Requirement already satisfied: pydantic<2.0.0 in /home/jovyan/.local/lib/python3.10/site-packages (from deepspeed) (1.10.8)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from deepspeed) (2.0.1+cu118)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from deepspeed) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.0.0->deepspeed) (4.5.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (3.9.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (3.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (2.0.0)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->deepspeed) (3.25.0)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->deepspeed) (15.0.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->deepspeed) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->deepspeed) (1.3.0)\n",
      "Building wheels for collected packages: deepspeed\n",
      "  Building wheel for deepspeed (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for deepspeed: filename=deepspeed-0.10.2-py3-none-any.whl size=898128 sha256=4a556ce6e2f4b0ce0f01342b79026294832fb281b622b53a2e41cc0decc34338\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/77/42/17/4b99c57aec4f66afc561bcb09007e1f0308b17cb81b7ae800a\n",
      "Successfully built deepspeed\n",
      "Installing collected packages: ninja, hjson, deepspeed\n",
      "Successfully installed deepspeed-0.10.2 hjson-3.1.0 ninja-1.11.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Package installations to work on WIRE\n",
    "\n",
    "! pip install transformers\n",
    "! pip install langchain\n",
    "! pip install accelerate\n",
    "! pip install einops\n",
    "! pip install deepspeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "86e77263-062c-44bc-8ace-6cf3a638e014",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, re, pandas as pd, numpy as np, ast, json\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm  \n",
    "\n",
    "import torch\n",
    "from langchain import PromptTemplate, FewShotPromptTemplate, HuggingFacePipeline, LLMChain\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "import deepspeed\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5057d3-9986-42e2-91f9-ccb0a8a782e5",
   "metadata": {},
   "source": [
    "# 1. Import and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ab8789ed-ab80-429d-a03e-6c07ac91a9d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file = os.path.join(\"semeval\",\"data_merged.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bdaa0228-553d-4169-a510-a8a974955d6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4e771931-ba00-487c-8c7a-dc68a435f86f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>event</th>\n",
       "      <th>full_text</th>\n",
       "      <th>stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>Atheism</td>\n",
       "      <td>dear lord thank u for all of ur blessings forg...</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102</td>\n",
       "      <td>Atheism</td>\n",
       "      <td>Blessed are the peacemakers, for they shall be...</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103</td>\n",
       "      <td>Atheism</td>\n",
       "      <td>I am not conformed to this world. I am transfo...</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104</td>\n",
       "      <td>Atheism</td>\n",
       "      <td>Salah should be prayed with #focus and #unders...</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105</td>\n",
       "      <td>Atheism</td>\n",
       "      <td>And stay in your houses and do not display you...</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id    event                                          full_text   \n",
       "0       101  Atheism  dear lord thank u for all of ur blessings forg...  \\\n",
       "1       102  Atheism  Blessed are the peacemakers, for they shall be...   \n",
       "2       103  Atheism  I am not conformed to this world. I am transfo...   \n",
       "3       104  Atheism  Salah should be prayed with #focus and #unders...   \n",
       "4       105  Atheism  And stay in your houses and do not display you...   \n",
       "\n",
       "     stance  \n",
       "0  disagree  \n",
       "1  disagree  \n",
       "2  disagree  \n",
       "3  disagree  \n",
       "4  disagree  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b6ceb2cd-e7cc-4c58-aa8e-1b42f6f7e3ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2814, 4)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a182cfb3-9a8d-4e44-8570-eb37c9a418a0",
   "metadata": {},
   "source": [
    "# 2. Connect to LLM\n",
    "- for standing up a smaller huggingface model\n",
    "```python\n",
    "llm = HuggingFacePipeline.from_model_id(model_id=\"declare-lab/flan-alpaca-gpt4-xl\", task = 'text2text-generation', device=0,\n",
    "                                      model_kwargs={\"max_length\":500, \"do_sample\":False})\n",
    "```\n",
    "- for a mid-sized, more modern, huggingface model. You can use accelerate and chance ``` device = \"auto\"``` to use multiple GPUs\n",
    "```python\n",
    "model = \"tiiuae/falcon-7b-instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "    device_map=0,\n",
    "    max_length=200,\n",
    "    do_sample=False,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=pipe)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a845955d-162c-4531-a774-231a465372f6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca2f04fcbdb24c01960021fbdd13879e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = \"declare-lab/flan-alpaca-xxl\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\",\n",
    "    max_length=1000,\n",
    "    do_sample=False,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403fdd62-677d-467f-b0d6-ef232fc9ca70",
   "metadata": {},
   "source": [
    "look at a few examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "750d3b59-d13a-45ce-8f09-ee1680c395a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AGAINST'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = '''What is the stance of of the following social media post toward the U.S. Army. Give the stance as either 'FOR', \"AGAINST', or 'NEUTRAL'. Only return the stance:\n",
    "\"@vondeveen If the Army wants to actually recruit people, maybe stop breaking people and actually prosecute sexual assualt #nomorewar.\"\n",
    "'''\n",
    "llm(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8539ac1f-1155-4e53-9837-2f311a898965",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NEUTRAL'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = '''What is the stance of of the following social media post toward the U.S. Army. Give the stance as either 'FOR', \"AGAINST', or 'NEUTRAL'. Only return the stance:\n",
    "\"@artfulask I have never seen a pink-eared duck before. #Army\"\n",
    "'''\n",
    "llm(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "283a5080-d9f4-4e95-81be-da898da57990",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FOR'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = '''What is the stance of of the following social media post toward the U.S. Army. Give the stance as either 'FOR', \"AGAINST', or 'NEUTRAL'. Only return the stance:\n",
    "\"I think the @Army helped me become disciplined. I would have surely flunked out of college chasing tail if I didn't get some discipline there. #SFL\"\n",
    "'''\n",
    "llm(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c99f07-4c5d-49a7-bac9-36a3399c2927",
   "metadata": {},
   "source": [
    "# 3. Prompt Engineering for Stance Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e692217e-d8cb-44c8-ab54-21c3c076d6ee",
   "metadata": {},
   "source": [
    "## 3(a). Task-only prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f5cefeed-4bcb-48a9-815f-7e02011e417a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# task-only prompt\n",
    "\n",
    "task_template = '''\n",
    "Classify the statement as to whether it is 'FOR', 'AGAINST', or 'NEUTRAL'. Only return the classification label for the statement, and no other text.\n",
    "\n",
    "statement: {statement}\n",
    "'''\n",
    "\n",
    "task_prompt = PromptTemplate(\n",
    "    input_variables=[\"statement\"],\n",
    "    template=task_template\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0486f1e-b948-4cf8-921b-756139394b11",
   "metadata": {},
   "source": [
    "### Run an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a23f26eb-0ade-4a4e-9a99-5f91c9075438",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a sample for all examples\n",
    "\n",
    "random_sample_df = df.sample(50)\n",
    "y_true = random_sample_df['stance'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d5a3a1f4-aac6-48be-8364-6e190ed49366",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "llm_chain = LLMChain(prompt=task_prompt, llm=llm)\n",
    "\n",
    "results=[]\n",
    "for row in random_sample_df.iterrows():\n",
    "    results.append(llm_chain.run(event=row[1]['event'], statement=row[1]['full_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9e436eb7-c2f2-41cd-b484-cc9160c4b1f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       agree       0.28      0.62      0.38         8\n",
      "    disagree       0.69      0.69      0.69        26\n",
      "     neutral       0.83      0.31      0.45        16\n",
      "\n",
      "    accuracy                           0.56        50\n",
      "   macro avg       0.60      0.54      0.51        50\n",
      "weighted avg       0.67      0.56      0.57        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# converting to given labels for comparison\n",
    "\n",
    "y_true = [str.lower(i) for i in y_true]\n",
    "y_pred = []  \n",
    "  \n",
    "for word in results:  \n",
    "    lower_word = word.lower()  \n",
    "    if 'for' in lower_word:  \n",
    "        y_pred.append('agree')  \n",
    "    elif 'against' in lower_word or 'denies' in lower_word:  \n",
    "        y_pred.append('disagree')  \n",
    "    elif 'neutral' in lower_word:  \n",
    "        y_pred.append('neutral')  \n",
    "    else:  \n",
    "        y_pred.append('neutral')\n",
    "\n",
    "# generating the classification report\n",
    "report = classification_report(y_true, y_pred)\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477aed9a-deec-40f1-85a3-fda877fb86c3",
   "metadata": {},
   "source": [
    "### Run on all Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2a3aa074-0261-4e3d-a57c-7313d9679bc4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "2814it [15:57,  2.94it/s]\n"
     ]
    }
   ],
   "source": [
    "# Running across the whole dataset\n",
    "\n",
    "results = []\n",
    "for index, row in tqdm(df.iterrows()):\n",
    "    results.append(llm_chain.run(event=row['event'], statement=row['full_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "63130b8a-c103-4df4-bb91-9d70213947fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['AAGAINST', 'AGAINST', 'AGGAINST', 'Against', 'FOR', 'NEG',\n",
       "        'NEUTRAL'], dtype='<U8'),\n",
       " array([  76, 1057,    1,   35, 1287,    1,  357]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(results, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c4cf24d7-ca26-4735-9a57-9cf826e0a286",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = []  \n",
    "  \n",
    "for word in results:  \n",
    "    lower_word = word.lower()  \n",
    "    if 'for' in lower_word:  \n",
    "        y_pred.append('agree')  \n",
    "    elif 'against' in lower_word or 'denies' in lower_word:  \n",
    "        y_pred.append('disagree')  \n",
    "    elif 'neutral' in lower_word:  \n",
    "        y_pred.append('neutral')  \n",
    "    else:  \n",
    "        y_pred.append('neutral')\n",
    "        \n",
    "df['task_preds'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e334043f-4a5f-4a40-813f-0021570ae054",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['agree', 'disagree', 'neutral'], dtype=object),\n",
       " array([1287, 1168,  359]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df['task_preds'], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "906f54ca-301b-442e-9c0e-776598a98063",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       agree       0.35      0.61      0.44       731\n",
      "    disagree       0.59      0.51      0.55      1342\n",
      "     neutral       0.46      0.22      0.30       741\n",
      "\n",
      "    accuracy                           0.46      2814\n",
      "   macro avg       0.47      0.45      0.43      2814\n",
      "weighted avg       0.49      0.46      0.46      2814\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(df['stance'], df['task_preds'])\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753eac3e-fba1-4615-bc84-6b576814fd28",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3(b). Context prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f23b18b6-82f8-4498-b9e1-5dbfb4662996",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# context prompt\n",
    "\n",
    "context_template = '''\n",
    "The following statement is a social media post expressing an opinion about an entity. Classify the statement as to whether it is 'FOR', 'AGAINST', or 'NEUTRAL' toward the entity below. Only return the classification label for the statement toward the entity, and no other text.\n",
    "\n",
    "entity: {event}\n",
    "statement: {statement}\n",
    "'''\n",
    "\n",
    "context_prompt = PromptTemplate(\n",
    "    input_variables=[\"event\",\"statement\"],\n",
    "    template=context_template\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76cda91-c949-4268-bfc8-39d3999eef46",
   "metadata": {},
   "source": [
    "### Run an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "70668cf6-2cb0-45bf-a14b-0541630a819c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "llm_chain = LLMChain(prompt=context_prompt, llm=llm)\n",
    "\n",
    "results=[]\n",
    "for row in random_sample_df.iterrows():\n",
    "    results.append(llm_chain.run(event=row[1]['event'], statement=row[1]['full_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "88aefc12-a867-4975-9340-46ec79d49122",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       agree       0.45      0.62      0.53         8\n",
      "    disagree       0.71      0.85      0.77        26\n",
      "     neutral       0.62      0.31      0.42        16\n",
      "\n",
      "    accuracy                           0.64        50\n",
      "   macro avg       0.60      0.59      0.57        50\n",
      "weighted avg       0.64      0.64      0.62        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# converting to given labels for comparison\n",
    "\n",
    "y_true = [str.lower(i) for i in y_true]\n",
    "y_pred = []  \n",
    "  \n",
    "for word in results:  \n",
    "    lower_word = word.lower()  \n",
    "    if 'for' in lower_word:  \n",
    "        y_pred.append('agree')  \n",
    "    elif 'against' in lower_word:  \n",
    "        y_pred.append('disagree')  \n",
    "    elif 'neutral' in lower_word:  \n",
    "        y_pred.append('neutral')  \n",
    "    else:  \n",
    "        y_pred.append('neutral')\n",
    "\n",
    "# generating the classification report  \n",
    "report = classification_report(y_true, y_pred)  \n",
    "  \n",
    "print(report)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d122fe57-c6a0-4f9f-88f2-ab3b033d4969",
   "metadata": {},
   "source": [
    "### Run on all Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "20dbad2c-32b1-4d2d-a7be-ed3833768633",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "2814it [17:58,  2.61it/s]\n"
     ]
    }
   ],
   "source": [
    "# Running across the whole dataset\n",
    "\n",
    "results = []\n",
    "for index, row in tqdm(df.iterrows()):\n",
    "    results.append(llm_chain.run(event=row['event'], statement=row['full_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cf183a8f-03b9-4145-8b8b-bd004fc88006",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['AAGAINST', 'AGAINST', 'Against', 'Atheism', 'FOR', 'NEUTRAL'],\n",
       "       dtype='<U8'),\n",
       " array([  35, 1390,   25,    1,  905,  458]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(results, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0da70805-b9b7-4840-9dbb-a31897733630",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = []  \n",
    "  \n",
    "for word in results:  \n",
    "    lower_word = word.lower()  \n",
    "    if 'for' in lower_word:  \n",
    "        y_pred.append('agree')  \n",
    "    elif 'against' in lower_word:  \n",
    "        y_pred.append('disagree')  \n",
    "    elif 'neutral' in lower_word:  \n",
    "        y_pred.append('neutral')  \n",
    "    else:  \n",
    "        y_pred.append('neutral')\n",
    "        \n",
    "df['context_preds'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4a9b196d-2158-40eb-9adb-84c62c5dcd53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['agree', 'disagree', 'neutral'], dtype=object),\n",
       " array([ 905, 1450,  459]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df['context_preds'], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e999ba12-0fa0-4204-bb0a-84376a5ab041",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       agree       0.56      0.69      0.62       731\n",
      "    disagree       0.70      0.75      0.73      1342\n",
      "     neutral       0.58      0.36      0.44       741\n",
      "\n",
      "    accuracy                           0.63      2814\n",
      "   macro avg       0.61      0.60      0.60      2814\n",
      "weighted avg       0.63      0.63      0.62      2814\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(df['stance'], df['context_preds'])\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a8755d-d895-49b1-bc13-1965215392fd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3(c). Context + FSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0407c388-7977-443d-beba-03c0faa2ab64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create an example template\n",
    "\n",
    "example_template = '''\n",
    "entity: {entity}\n",
    "statement: {statement}\n",
    "stance: {stance}\n",
    "'''\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"entity\",\"statement\", \"stance\"],\n",
    "    template=example_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1cfae949-c846-4f0f-b31a-f84d30e54be9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Give some examples\n",
    "\n",
    "examples = [\n",
    "    {'entity':\"Atheism\",\n",
    "     'statement':\"Leaving Christianity enables you to love the people you once rejected. #freethinker #Christianity #SemST\",\n",
    "     'stance': 'FOR'},\n",
    "    {'entity':\"Climate Change is a Real Concern\",\n",
    "     'statement':\"@AlharbiF I'll bomb anything I can get my hands on, especially if THEY aren't christian. #graham2016 #GOP #SemST\",\n",
    "     'stance': 'NEUTRAL'},\n",
    "    {'entity':\"Feminist Movement\",\n",
    "     'statement':\"Always a delight to see chest-drumming alpha males hiss and scuttle backwards up the wall when a feminist enters the room. #manly #SemST\",\n",
    "     'stance': 'FOR'},\n",
    "    {'entity':\"Hillary Clinton\",\n",
    "     'statement':\"Would you wanna be in a long term relationship with some bitch that hides her emails, & lies to your face? Then #Dontvote #SemST\",\n",
    "     'stance': 'AGAINST'},\n",
    "    {'entity':\"Legalization of Abortion\",\n",
    "     'statement':\"@k_yoder That lady needs help, mental illness is a serious issue. #SemST\",\n",
    "     'stance': 'NEUTRAL'},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6ec3f4a3-be9d-46df-bed7-8b2afa937000",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prefix = \"\"\"\n",
    "The following statements are social media posts expressing opinions about an entities. Each statement can either be 'FOR', 'AGAINST', or 'NEUTRAL' toward their associated entity.\n",
    "\"\"\"\n",
    "\n",
    "suffix = '''\n",
    "Now, classify the following statement as to whether it is 'FOR', 'AGAINST', or 'NEUTRAL' toward the entity below. Only return the classification label for the statement toward the entity, and no other text.\n",
    "\n",
    "entity: {event}\n",
    "statement: {statement}\n",
    "'''\n",
    "\n",
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"event\", \"statement\"],\n",
    "    example_separator=\"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6c9f10-3438-446e-9812-f4d1a1e70c1b",
   "metadata": {},
   "source": [
    "### Run an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "14e63860-b15e-4b0f-89be-16ef75f83c3e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "llm_chain = LLMChain(prompt=few_shot_prompt, llm=llm)\n",
    "\n",
    "results=[]\n",
    "for row in random_sample_df.iterrows():\n",
    "    results.append(llm_chain.run(event=row[1]['event'], statement=row[1]['full_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "48e8de6c-a692-4a13-a94a-a94ce0404006",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       agree       0.50      0.50      0.50         8\n",
      "    disagree       0.72      0.81      0.76        26\n",
      "     neutral       0.69      0.56      0.62        16\n",
      "\n",
      "    accuracy                           0.68        50\n",
      "   macro avg       0.64      0.62      0.63        50\n",
      "weighted avg       0.68      0.68      0.68        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# converting to given labels for comparison\n",
    "\n",
    "y_true = [str.lower(i) for i in y_true]\n",
    "y_pred = []  \n",
    "  \n",
    "for word in results:  \n",
    "    lower_word = word.lower()  \n",
    "    if 'for' in lower_word:  \n",
    "        y_pred.append('agree')  \n",
    "    elif 'against' in lower_word:  \n",
    "        y_pred.append('disagree')  \n",
    "    elif 'neutral' in lower_word:  \n",
    "        y_pred.append('neutral')  \n",
    "    else:  \n",
    "        y_pred.append('neutral')\n",
    "\n",
    "# generating the classification report  \n",
    "report = classification_report(y_true, y_pred)  \n",
    "  \n",
    "print(report)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0622d58d-9df3-4a17-8d22-244df05436de",
   "metadata": {},
   "source": [
    "### Run on all Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bc5169c2-4b07-4237-baf3-af889bdf11e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "2814it [35:24,  1.32it/s]\n"
     ]
    }
   ],
   "source": [
    "# Running across the whole dataset\n",
    "\n",
    "results = []\n",
    "for index, row in tqdm(df.iterrows()):\n",
    "    results.append(llm_chain.run(event=row['event'], statement=row['full_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "beda45b7-f275-4fa3-b59d-9009b51d6682",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['AGAINST', 'Against', 'Atheism', 'FOR', 'NEUTRAL'], dtype='<U7'),\n",
       " array([1352,    4,    1,  791,  666]))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(results, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7dc5c63a-b901-4541-81dd-e69985f36460",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = []  \n",
    "  \n",
    "for word in results:  \n",
    "    lower_word = word.lower()  \n",
    "    if 'for' in lower_word:  \n",
    "        y_pred.append('agree')  \n",
    "    elif 'against' in lower_word:  \n",
    "        y_pred.append('disagree')  \n",
    "    elif 'neutral' in lower_word:  \n",
    "        y_pred.append('neutral')  \n",
    "    else:  \n",
    "        y_pred.append('neutral')\n",
    "        \n",
    "df['fsp_preds'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a1521a68-6865-496e-87e1-5990887725a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['agree', 'disagree', 'neutral'], dtype=object),\n",
       " array([ 791, 1356,  667]))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df['fsp_preds'], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "050cbe93-765c-4b30-bd7a-c8d293b99dff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       agree       0.61      0.66      0.64       731\n",
      "    disagree       0.71      0.72      0.71      1342\n",
      "     neutral       0.47      0.43      0.45       741\n",
      "\n",
      "    accuracy                           0.63      2814\n",
      "   macro avg       0.60      0.60      0.60      2814\n",
      "weighted avg       0.62      0.63      0.62      2814\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(df['stance'], df['fsp_preds'])\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b658afe0-4555-496c-b244-b00039433330",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3(d). Context + FSP + Reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "940202db-ae18-42ca-9f75-2061b4281e44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create an example template\n",
    "\n",
    "example_and_reason_template = '''\n",
    "entity: {entity}\n",
    "statement: {statement}\n",
    "stance: {stance}\n",
    "reason: {reason}\n",
    "'''\n",
    "\n",
    "example_and_reason_prompt = PromptTemplate(\n",
    "    input_variables=[\"entity\",\"statement\", \"stance\", \"reason\"],\n",
    "    template=example_and_reason_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "32e90a11-7697-4ee8-abd1-7dedbc3c0f47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Give some examples\n",
    "\n",
    "examples = [\n",
    "    {'entity':\"Atheism\",\n",
    "     'statement':'''Leaving Christianity enables you to love the people you once rejected. #freethinker #Christianity #SemST''',\n",
    "     'stance': 'FOR',\n",
    "     'reason': \"the statement is for atheism as it claims leaving a religion like christianity makes one more loving.\"\n",
    "    },\n",
    "    {'entity':\"Climate Change is a Real Concern\",\n",
    "     'statement':'''@AlharbiF I'll bomb anything I can get my hands on, especially if THEY aren't christian. #graham2016 #GOP #SemST''',\n",
    "     'stance': 'NEUTRAL',\n",
    "     'reason': \"the statement does not explicity reference climate change and it is not clear who the author would bomb, so it is neutral toward climate change.\"\n",
    "    },\n",
    "    {'entity':\"Feminist Movement\",\n",
    "     'statement':'''Always a delight to see chest-drumming alpha males hiss and scuttle backwards up the wall when a feminist enters the room. #manly #SemST''',\n",
    "     'stance': 'FOR',\n",
    "     'reason': \"the statement supports the feminist movement as it makes fun of alpha males, who are typically seen as being against feminism.\"\n",
    "    },\n",
    "    {'entity':\"Hillary Clinton\",\n",
    "     'statement':'''Would you wanna be in a long term relationship with some bitch that hides her emails, & lies to your face? Then #Dontvote #SemST''',\n",
    "     'stance': 'AGAINST',\n",
    "     'reason': \"the statement is against Hillary Clinton as it calles her a bitch and claims she does bad things like hides emails and lies.\"\n",
    "    },\n",
    "    {'entity':\"Legalization of Abortion\",\n",
    "     'statement':'''@k_yoder That lady needs help, mental illness is a serious issue. #SemST''',\n",
    "     'stance': 'NEUTRAL',\n",
    "     'reason': \"the statement is neutral toward legalization of abortion as it does not talk about abortion and its not clear if the mentioned lady is related to abortion at all.\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "58c0a06d-0604-445e-89b3-7807b6a60685",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prefix = \"\"\"\n",
    "The following statements are social media posts expressing opinions about an entities. Each statement can either be 'FOR', 'AGAINST', or 'NEUTRAL' toward their associated entity and includes the reason why they have that stance.\n",
    "\"\"\"\n",
    "\n",
    "suffix = '''\n",
    "Now, classify the following statement as to whether it is 'FOR', 'AGAINST', or 'NEUTRAL' toward the entity below and give your reasoning. Only return the classification label for the statement toward the target and the reason for the classification label in the form of: 'stance: STANCE, reason: REASON'\n",
    "\n",
    "entity: {event}\n",
    "statement: {statement}\n",
    "'''\n",
    "\n",
    "few_shot_and_reason_prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_and_reason_prompt,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"event\", \"statement\"],\n",
    "    example_separator=\"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13aabfb6-da64-4d33-b501-d24e5e0c41e8",
   "metadata": {},
   "source": [
    "### Run an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0b2606a6-dc35-45a4-aa4c-a9d0cdb733e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (576 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "llm_chain = LLMChain(prompt=few_shot_and_reason_prompt, llm=llm)\n",
    "\n",
    "results=[]\n",
    "for row in random_sample_df.iterrows():\n",
    "    results.append(llm_chain.run(event=row[1]['event'], statement=row[1]['full_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "711e81c2-c074-4a35-8c93-a0b2575f8bb4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       agree       0.29      0.88      0.44         8\n",
      "    disagree       0.72      0.69      0.71        26\n",
      "     neutral       1.00      0.06      0.12        16\n",
      "\n",
      "    accuracy                           0.52        50\n",
      "   macro avg       0.67      0.54      0.42        50\n",
      "weighted avg       0.74      0.52      0.47        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = []  \n",
    "reasons = []  \n",
    "  \n",
    "for result in results:  \n",
    "    split_result = result.split('reason:')  \n",
    "    if len(split_result) == 2:  \n",
    "        # Extract stance and reason, remove leading/trailing whitespace and convert stance to lowercase  \n",
    "        stance, reason = split_result\n",
    "        stance = stance.replace('stance:', '').replace(',', '').strip().lower()\n",
    "        reason = reason.strip()\n",
    "        reasons.append(reason)\n",
    "    else:\n",
    "        # model did not give a reason\n",
    "        stance = split_result[0]\n",
    "        stance = stance.replace('stance:', '').replace(',', '').strip().lower()\n",
    "        reasons.append('')\n",
    "    if 'for' in stance:  \n",
    "        y_pred.append('agree')  \n",
    "    elif 'against' in stance:  \n",
    "        y_pred.append('disagree')  \n",
    "    elif 'neutral' in stance:  \n",
    "        y_pred.append('neutral')\n",
    "    else:  \n",
    "        y_pred.append('neutral')\n",
    "\n",
    "y_true = [str.lower(i) for i in y_true]\n",
    "\n",
    "# generating the classification report\n",
    "report = classification_report(y_true, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e47e691-8ef2-4cae-adf7-4e0211f04e5a",
   "metadata": {},
   "source": [
    "### Run on all Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2d04c4ca-471d-46a1-896b-c26d61ba93e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "2814it [3:54:55,  5.01s/it]\n"
     ]
    }
   ],
   "source": [
    "# Running across the whole dataset\n",
    "\n",
    "results = []\n",
    "for index, row in tqdm(df.iterrows()):\n",
    "    results.append(llm_chain.run(event=row['event'], statement=row['full_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "97157b49-ef39-4c4d-9e1f-782eeafd3d9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = []  \n",
    "reasons = []  \n",
    "  \n",
    "for result in results:  \n",
    "    split_result = result.split('reason:')  \n",
    "    if len(split_result) == 2:  \n",
    "        # Extract stance and reason, remove leading/trailing whitespace and convert stance to lowercase  \n",
    "        stance, reason = split_result\n",
    "        stance = stance.replace('stance:', '').replace(',', '').strip().lower()\n",
    "        reason = reason.strip()\n",
    "        reasons.append(reason)\n",
    "    else:\n",
    "        # model did not give a reason\n",
    "        stance = split_result[0]\n",
    "        stance = stance.replace('stance:', '').replace(',', '').strip().lower()\n",
    "        reasons.append('')\n",
    "    if 'for' in stance:  \n",
    "        y_pred.append('agree')  \n",
    "    elif 'against' in stance:  \n",
    "        y_pred.append('disagree')  \n",
    "    elif 'neutral' in stance:  \n",
    "        y_pred.append('neutral')\n",
    "    else:  \n",
    "        y_pred.append('neutral')\n",
    "        \n",
    "df['fsp_reason_preds'] = y_pred\n",
    "df['fsp_reason_reasons'] = reasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b02b73fb-2ec0-49f1-b0a2-baeef114f4cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['agree', 'disagree', 'neutral'], dtype=object),\n",
       " array([1374, 1328,  112]))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df['fsp_reason_preds'], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e44d2f6c-78b5-4740-9415-65c460ee3220",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       agree       0.44      0.82      0.57       731\n",
      "    disagree       0.68      0.67      0.68      1342\n",
      "     neutral       0.75      0.11      0.20       741\n",
      "\n",
      "    accuracy                           0.57      2814\n",
      "   macro avg       0.62      0.54      0.48      2814\n",
      "weighted avg       0.64      0.57      0.52      2814\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(df['stance'], df['fsp_reason_preds'])\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d03aa11f-e001-4907-bd66-e989a653c0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"semeval_flan-alpaca-11B_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94de7d2f-b6db-4714-8efe-f7cc1357b831",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
