{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b37c7bb-c037-4504-a2e2-4010b3726ac8",
   "metadata": {},
   "source": [
    "# Stance Classification for PhemeRumors\n",
    "- read in the data and pre-process\n",
    "- set up an LLM\n",
    "- Investigate different prompting schemes\n",
    "    - just context\n",
    "    - context + few-shot learning\n",
    "    - content + few-shot learning + reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "5b436af4-75ff-4598-a9e3-70e746e1f99d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /home/jovyan/.local/lib/python3.10/site-packages (0.27.6)\n",
      "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.30.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.5.7)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: langchain in /home/jovyan/.local/lib/python3.10/site-packages (0.0.158)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.13)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.4)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.2)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /home/jovyan/.local/lib/python3.10/site-packages (from langchain) (0.5.7)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.4)\n",
      "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
      "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /home/jovyan/.local/lib/python3.10/site-packages (from langchain) (1.2.4)\n",
      "Requirement already satisfied: pydantic<2,>=1 in /home/jovyan/.local/lib/python3.10/site-packages (from langchain) (1.10.8)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.30.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/jovyan/.local/lib/python3.10/site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: tqdm>=4.48.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.65.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /home/jovyan/.local/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.19.0)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /home/jovyan/.local/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (1.5.1)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in /home/jovyan/.local/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.8.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1->langchain) (4.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.5.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.3->langchain) (2.0.2)\n",
      "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.22.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1+cu118)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.0.0)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (3.25.0)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (15.0.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Collecting einops\n",
      "  Using cached einops-0.6.1-py3-none-any.whl (42 kB)\n",
      "Installing collected packages: einops\n",
      "Successfully installed einops-0.6.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Package installations to work on WIRE\n",
    "\n",
    "! pip install openai\n",
    "! pip install langchain\n",
    "! pip install accelerate\n",
    "! pip install einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "86e77263-062c-44bc-8ace-6cf3a638e014",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, re, pandas as pd, numpy as np, openai, ast, json\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm  \n",
    "\n",
    "import torch\n",
    "from langchain import OpenAI, PromptTemplate, FewShotPromptTemplate, HuggingFacePipeline, LLMChain\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5057d3-9986-42e2-91f9-ccb0a8a782e5",
   "metadata": {},
   "source": [
    "# 1. Import and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab8789ed-ab80-429d-a03e-6c07ac91a9d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file = os.path.join(\"phemerumours\",\"data_merged.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdaa0228-553d-4169-a510-a8a974955d6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e771931-ba00-487c-8c7a-dc68a435f86f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>stance</th>\n",
       "      <th>event</th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>576755174531862529</td>\n",
       "      <td>agree</td>\n",
       "      <td>putinmissing</td>\n",
       "      <td>Coup? RT @jimgeraghty: Rumors all Russian mili...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>576319832800555008</td>\n",
       "      <td>agree</td>\n",
       "      <td>putinmissing</td>\n",
       "      <td>Hoppla! @L0gg0l: Swiss Rumors: Putin absence d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>576513463738109954</td>\n",
       "      <td>disagree</td>\n",
       "      <td>putinmissing</td>\n",
       "      <td>Putin reappears on TV amid claims he is unwell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>552783667052167168</td>\n",
       "      <td>agree</td>\n",
       "      <td>charliehebdo</td>\n",
       "      <td>France: 10 people dead after shooting at HQ of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>552793679082311680</td>\n",
       "      <td>agree</td>\n",
       "      <td>charliehebdo</td>\n",
       "      <td>11 confirmed dead, Francois Hollande to visit ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id    stance         event   \n",
       "0  576755174531862529     agree  putinmissing  \\\n",
       "1  576319832800555008     agree  putinmissing   \n",
       "2  576513463738109954  disagree  putinmissing   \n",
       "3  552783667052167168     agree  charliehebdo   \n",
       "4  552793679082311680     agree  charliehebdo   \n",
       "\n",
       "                                           full_text  \n",
       "0  Coup? RT @jimgeraghty: Rumors all Russian mili...  \n",
       "1  Hoppla! @L0gg0l: Swiss Rumors: Putin absence d...  \n",
       "2  Putin reappears on TV amid claims he is unwell...  \n",
       "3  France: 10 people dead after shooting at HQ of...  \n",
       "4  11 confirmed dead, Francois Hollande to visit ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6ceb2cd-e7cc-4c58-aa8e-1b42f6f7e3ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2859, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8ce9d8c-8db7-4a90-bd5d-c5ada923046b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a dictionary with the original values as keys and new values as corresponding values  \n",
    "event_dict = {  \n",
    "    'putinmissing': \"Russian President Putin has gone missing\",   \n",
    "    'charliehebdo': \"there was a shooting event at Charlie Hebdo in Paris\",   \n",
    "    'prince-toronto': \"singer Prince will play a secret show in Toronto\",   \n",
    "    'ferguson': \"There is unrest in Ferguson, Missouri\",   \n",
    "    'germanwings-crash': \"A Germanwings plane crashed\",   \n",
    "    'ottawashooting': \"There was a shooting event in Ottawa\",   \n",
    "    'sydneysiege': \"There is a hostage situation in Sydney\",   \n",
    "    'ebola-essien': \"Michael Essien contracted Ebola\"  \n",
    "}  \n",
    "  \n",
    "# Use the map function to replace the values  \n",
    "df['event'] = df['event'].map(event_dict)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a182cfb3-9a8d-4e44-8570-eb37c9a418a0",
   "metadata": {},
   "source": [
    "# 2. Connect to LLM\n",
    "- for connectiong to Open AI\n",
    "```python\n",
    "with open(\"../aci_openai_credentials.txt\") as f:\n",
    "    open_api_base, open_api_key = f.read().split(\"\\n\")\n",
    "\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = open_api_base\n",
    "openai.api_version = \"2023-03-15-preview\"\n",
    "openai.api_key = open_api_key\n",
    "```\n",
    "- for standing up a smaller huggingface model\n",
    "```python\n",
    "llm = HuggingFacePipeline.from_model_id(model_id=\"declare-lab/flan-alpaca-gpt4-xl\", task = 'text2text-generation', device=0,\n",
    "                                      model_kwargs={\"max_length\":500, \"do_sample\":False})\n",
    "```\n",
    "- for a mid-sized, more modern, huggingface model. You can use accelerate and chance ``` device = \"auto\"``` to use multiple GPUs\n",
    "```python\n",
    "model = \"tiiuae/falcon-7b-instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "    device_map=0,\n",
    "    max_length=200,\n",
    "    do_sample=False,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=pipe)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a845955d-162c-4531-a774-231a465372f6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"../personal_openai_key.txt\") as f:\n",
    "    open_api_key = f.read()\n",
    "    \n",
    "openai.api_key = open_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "750d3b59-d13a-45ce-8f09-ee1680c395a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AGAINST'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = '''What is the stance of the author of the following toward the U.S. Army. Give the stance as either 'FOR', \"AGAINST', or 'NEUTRAL'. Only return the stance:\n",
    "\"@vondeveen If the Army wants to actually recruit people, maybe stop breaking people and actually prosecute sexual assualt #nomorewar.\"\n",
    "'''\n",
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages = [{\"role\":\"user\",\"content\":question}],\n",
    "  temperature=0.1,\n",
    "  max_tokens=50,\n",
    "  stop=None)\n",
    "\n",
    "response.choices[0].message['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8539ac1f-1155-4e53-9837-2f311a898965",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NEUTRAL'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = '''What is the stance of the author of the following toward the U.S. Army. Give the stance only as either 'FOR', \"AGAINST', or 'NEUTRAL'. Only return the stance:\n",
    "\"@artfulask I have never seen a pink-eared duck before. #Army\"\n",
    "'''\n",
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages = [{\"role\":\"user\",\"content\":question}],\n",
    "  temperature=0.1,\n",
    "  max_tokens=50,\n",
    "  stop=None)\n",
    "\n",
    "response.choices[0].message['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "283a5080-d9f4-4e95-81be-da898da57990",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FOR'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = '''What is the stance of the author of the following toward the U.S. Army. Give the stance as either 'FOR', \"AGAINST', or 'NEUTRAL'. Only return the stance:\n",
    "\"I think the @Army helped me become disciplined. I would have surely flunked out of college chasing tail if I didn't get some discipline there. #SFL\"\n",
    "'''\n",
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages = [{\"role\":\"user\",\"content\":question}],\n",
    "  temperature=0.1,\n",
    "  max_tokens=50,\n",
    "  stop=None)\n",
    "\n",
    "response.choices[0].message['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c99f07-4c5d-49a7-bac9-36a3399c2927",
   "metadata": {},
   "source": [
    "# 3. Prompt Engineering for Stance Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753eac3e-fba1-4615-bc84-6b576814fd28",
   "metadata": {},
   "source": [
    "## 3(a). Context-only prompt\n",
    "- prompt for single comment at a time\n",
    "```python\n",
    "context_template = '''\n",
    "The following statement is a social media commenting on wether an event, \"{event}\", is true. Classify the statement as to wether it \"AGREE\", \"DISAGREE\", or is \"NEUTRAL\" toward event \"{event}\" being true. Only return the classification label of \"AGREE\", \"DISAGREE\", or \"NEUTRAL\" for the statement, and no other text.\n",
    "\n",
    "statement: {statement}\n",
    "classification:\n",
    "'''\n",
    "\n",
    "context_prompt = PromptTemplate(\n",
    "    input_variables=[\"event\",\"statement\"],\n",
    "    template=context_template\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f23b18b6-82f8-4498-b9e1-5dbfb4662996",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# context prompt\n",
    "\n",
    "context_template = '''\n",
    "The following statements are from social media and are commenting on wether an event, \"{event}\", happened. Classify each of the statements as to wether they \"AGREE\", \"DISAGREE\", or are \"NEUTRAL\" toward event \"{event}\" happening. Only return the classification label for all of the statements, and no other text.\n",
    "\n",
    "statements:\n",
    "{statements}\n",
    "'''\n",
    "\n",
    "context_prompt = PromptTemplate(\n",
    "    input_variables=[\"event\",\"statements\"],\n",
    "    template=context_template\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76cda91-c949-4268-bfc8-39d3999eef46",
   "metadata": {},
   "source": [
    "### Run an example\n",
    "\n",
    "- To do this with openAI:\n",
    "```python\n",
    "response = openai.ChatCompletion.create(\n",
    "  engine=\"ACI_GPT-4\",\n",
    "  messages = [{\"role\":\"user\",\"content\":context_prompt.format(event = event, statements=statements)}],\n",
    "  temperature=0.8,\n",
    "  max_tokens=800,\n",
    "  top_p=0.95,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0,\n",
    "  stop=None)\n",
    "\n",
    "y_pred = response.choices[0].message['content']\n",
    "```\n",
    "- To do this with a local model\n",
    "```python\n",
    "llm_chain = LLMChain(prompt=context_prompt, llm=llm)\n",
    "\n",
    "results=[]\n",
    "for statement in statements:\n",
    "    results.append(llm_chain.run(event=event, statement=statement))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "17a0143a-cad6-45f7-845e-e90ed6dccd43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "event = df['event'][0]\n",
    "statements = df[df['event'] == event]['full_text'][0:20].tolist()\n",
    "y_true = df[df['event'] == event]['stance'][0:20].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "13ee5e07-ca7f-4ccc-98c3-29b230284adf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-4\",\n",
    "  messages = [{\"role\":\"user\",\"content\":context_prompt.format(event = event, statements=statements)}],\n",
    "  stop=None)\n",
    "\n",
    "results = response.choices[0].message['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "88aefc12-a867-4975-9340-46ec79d49122",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       agree       0.80      0.80      0.80         5\n",
      "    disagree       0.50      1.00      0.67         1\n",
      "     neutral       1.00      0.93      0.96        14\n",
      "\n",
      "    accuracy                           0.90        20\n",
      "   macro avg       0.77      0.91      0.81        20\n",
      "weighted avg       0.93      0.90      0.91        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# converting to lowercase\n",
    "y_true = [str.lower(i) for i in y_true]\n",
    "y_pred = [word.lower() for word in ast.literal_eval(results)]\n",
    "\n",
    "# generating the classification report  \n",
    "report = classification_report(y_true, y_pred)  \n",
    "  \n",
    "print(report)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d122fe57-c6a0-4f9f-88f2-ab3b033d4969",
   "metadata": {},
   "source": [
    "### Run on all Data\n",
    "- To do this OpenAI and multiple statements per query:\n",
    "```python\n",
    "df['fsp_preds'] =''\n",
    "num_statements_per_prompt = 20\n",
    "\n",
    "for event in df['event'].unique():\n",
    "    all_statements = df[df['event'] == event]['full_text'].tolist()\n",
    "    preds = []\n",
    "    print(\"event: {}, has {} statements\".format(event, len(all_statements)))\n",
    "    for statements in [all_statements[idx:idx+num_statements_per_prompt] for idx in range(0, len(all_statements), num_statements_per_prompt)]:\n",
    "\n",
    "        response = openai.ChatCompletion.create(\n",
    "          engine=\"ACI_GPT-4\",\n",
    "          messages = [{\"role\":\"user\",\"content\":few_shot_prompt.format(event = event, statements=statements)}],\n",
    "          temperature=0.8,\n",
    "          max_tokens=800,\n",
    "          top_p=0.95,\n",
    "          frequency_penalty=0,\n",
    "          presence_penalty=0,\n",
    "          stop=None)\n",
    "        \n",
    "        results = [str.lower(i) for i in ast.literal_eval(response.choices[0].message['content'])][:num_statements_per_prompt]\n",
    "        preds += results\n",
    "    df.loc[df['event'] == event, 'fsp_preds'] = preds  \n",
    "```\n",
    "- Run on a single statement with a local model\n",
    "```python\n",
    "# Running across the whole dataset\n",
    "\n",
    "results = []\n",
    "for index, row in tqdm(df.iterrows()):\n",
    "    results.append(llm_chain.run(event=row['event'], statement=row['full_text']))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "20dbad2c-32b1-4d2d-a7be-ed3833768633",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event: Russian President Putin has gone missing, has 46 statements\n",
      "event: there was a shooting event at Charlie Hebdo in Paris, has 711 statements\n",
      "event: singer Prince will play a secret show in Toronto, has 78 statements\n",
      "event: There is unrest in Ferguson, Missouri, has 694 statements\n",
      "event: A Germanwings plane crashed, has 209 statements\n",
      "event: There was a shooting event in Ottawa, has 482 statements\n",
      "event: There is a hostage situation in Sydney, has 623 statements\n",
      "event: Michael Essien contracted Ebola, has 16 statements\n"
     ]
    }
   ],
   "source": [
    "df['context_preds'] =''\n",
    "num_statements_per_prompt = 20\n",
    "\n",
    "for event in df['event'].unique():\n",
    "    all_statements = df[df['event'] == event]['full_text'].tolist()\n",
    "    preds = []\n",
    "    print(\"event: {}, has {} statements\".format(event, len(all_statements)))\n",
    "    for statements in [all_statements[idx:idx+num_statements_per_prompt] for idx in range(0, len(all_statements), num_statements_per_prompt)]:\n",
    "\n",
    "        response = openai.ChatCompletion.create(\n",
    "          model=\"gpt-4\",\n",
    "          messages = [{\"role\":\"user\",\"content\":context_prompt.format(event = event, statements=statements)}],\n",
    "          stop=None)\n",
    "        \n",
    "        results = [str.lower(i) for i in ast.literal_eval(response.choices[0].message['content'])][:num_statements_per_prompt]\n",
    "        preds += results\n",
    "    df.loc[df['event'] == event, 'context_preds'] = preds  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "4a9b196d-2158-40eb-9adb-84c62c5dcd53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['agree', 'disagree', 'neutral'], dtype=object),\n",
       " array([1369,   56, 1434]))"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df['context_preds'], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e999ba12-0fa0-4204-bb0a-84376a5ab041",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       agree       0.16      0.90      0.27       238\n",
      "    disagree       0.04      0.22      0.06         9\n",
      "     neutral       0.98      0.54      0.70      2612\n",
      "\n",
      "    accuracy                           0.57      2859\n",
      "   macro avg       0.39      0.56      0.34      2859\n",
      "weighted avg       0.91      0.57      0.66      2859\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(df['stance'], df['context_preds'])\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a8755d-d895-49b1-bc13-1965215392fd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3(b). Context + FSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "0407c388-7977-443d-beba-03c0faa2ab64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create an example template\n",
    "\n",
    "example_template = '''\n",
    "event: {event}\n",
    "statement: {statement}\n",
    "stance: {stance}\n",
    "'''\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"event\",\"statement\", \"stance\"],\n",
    "    template=example_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "1cfae949-c846-4f0f-b31a-f84d30e54be9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Give some examples\n",
    "\n",
    "examples = [\n",
    "    {'event':\"Putin has gone missing\",\n",
    "     'statement':\"Putin reappears on TV amid claims he is unwell and under threat of coup http://t.co/YZln23EUx1 http://t.co/ZsAnBa5gz3\",\n",
    "     'stance': 'DISAGREE'},\n",
    "    {'event':\"Michael Essien contracted Ebola\",\n",
    "     'statement': '''What? \"@FootballcomEN: Unconfirmed reports claim that Michael Essien has contracted Ebola. http://t.co/GsEizhwaV7\"''',\n",
    "     'stance': 'NEUTRAL'},\n",
    "    {'event':\"A Germanwings plane crashed\",\n",
    "     'statement': '''@thatjohn @planefinder why would they say urgence in lieu of mayday which is standard ?''',\n",
    "     'stance': 'NEUTRAL'},\n",
    "    {'event':\"There is a hostage situation in Sydney\",\n",
    "     'statement': '''@KEEMSTARx dick head it's not confirmed its Jihadist extremists. Don't speculate''',\n",
    "     'stance': 'NEUTRAL'},\n",
    "    {'event':\"singer Prince will play a secret show in Toronto\",\n",
    "     'statement': '''OMG. #Prince rumoured to be performing in Toronto today. Exciting!''',\n",
    "     'stance': 'AGREE'}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "88d60202-495d-4449-8dd6-3e984b03c0df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prefix = \"\"\"\n",
    "The following statements are examples of the stance of a social media comments towards wether an event happened or not.\n",
    "\"\"\"\n",
    "\n",
    "suffix = '''\n",
    "Now, classify each of the statements as to wether they \"AGREE\", \"DISAGREE\", or are \"NEUTRAL\" toward event \"{event}\" happening. Only return the classification label for all of the statements, and no other text.\n",
    "\n",
    "statements:\n",
    "{statements}\n",
    "'''\n",
    "\n",
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"event\", \"statements\"],\n",
    "    example_separator=\"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6c9f10-3438-446e-9812-f4d1a1e70c1b",
   "metadata": {},
   "source": [
    "### Run an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "e66f40a8-3653-4ce5-be9c-aa64c49d28a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "event = df['event'][0]\n",
    "statements = df[df['event'] == event]['full_text'][0:20].tolist()\n",
    "y_true = df[df['event'] == event]['stance'][0:20].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "14e63860-b15e-4b0f-89be-16ef75f83c3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-4\",\n",
    "  messages = [{\"role\":\"user\",\"content\":few_shot_prompt.format(event = event, statements=statements)}],\n",
    "  stop=None)\n",
    "\n",
    "results = response.choices[0].message['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "dbfdee7f-175e-4f87-a7f4-0e5f35625055",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['AGREE', 'AGREE', 'DISAGREE', 'AGREE', 'AGREE', 'AGREE', 'DISAGREE', 'NEUTRAL', 'NEUTRAL', 'NEUTRAL', 'NEUTRAL', 'NEUTRAL', 'NEUTRAL', 'NEUTRAL', 'NEUTRAL', 'NEUTRAL', 'NEUTRAL', 'NEUTRAL', 'NEUTRAL', 'NEUTRAL']\""
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "48e8de6c-a692-4a13-a94a-a94ce0404006",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       agree       0.80      0.80      0.80         5\n",
      "    disagree       0.50      1.00      0.67         1\n",
      "     neutral       1.00      0.93      0.96        14\n",
      "\n",
      "    accuracy                           0.90        20\n",
      "   macro avg       0.77      0.91      0.81        20\n",
      "weighted avg       0.93      0.90      0.91        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# converting to lowercase\n",
    "y_true = [str.lower(i) for i in y_true]\n",
    "y_pred = [word.lower() for word in ast.literal_eval(results)]\n",
    "\n",
    "# generating the classification report\n",
    "report = classification_report(y_true, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0622d58d-9df3-4a17-8d22-244df05436de",
   "metadata": {},
   "source": [
    "### Run on all Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "bc5169c2-4b07-4237-baf3-af889bdf11e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event: Russian President Putin has gone missing, has 46 statements\n",
      "event: there was a shooting event at Charlie Hebdo in Paris, has 711 statements\n",
      "event: singer Prince will play a secret show in Toronto, has 78 statements\n",
      "event: There is unrest in Ferguson, Missouri, has 694 statements\n",
      "event: A Germanwings plane crashed, has 209 statements\n",
      "event: There was a shooting event in Ottawa, has 482 statements\n",
      "event: There is a hostage situation in Sydney, has 623 statements\n",
      "event: Michael Essien contracted Ebola, has 16 statements\n"
     ]
    }
   ],
   "source": [
    "df['fsp_preds'] =''\n",
    "num_statements_per_prompt = 20\n",
    "\n",
    "for event in df['event'].unique():\n",
    "    all_statements = df[df['event'] == event]['full_text'].tolist()\n",
    "    preds = []\n",
    "    print(\"event: {}, has {} statements\".format(event, len(all_statements)))\n",
    "    for statements in [all_statements[idx:idx+num_statements_per_prompt] for idx in range(0, len(all_statements), num_statements_per_prompt)]:\n",
    "\n",
    "        response = openai.ChatCompletion.create(\n",
    "          model=\"gpt-4\",\n",
    "          messages = [{\"role\":\"user\",\"content\":few_shot_prompt.format(event = event, statements=statements)}],\n",
    "          stop=None)\n",
    "        \n",
    "        results = [str.lower(i) for i in ast.literal_eval(response.choices[0].message['content'])][:num_statements_per_prompt]\n",
    "        preds += results\n",
    "    df.loc[df['event'] == event, 'fsp_preds'] = preds  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "7dc5c63a-b901-4541-81dd-e69985f36460",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['agree', 'disagree', 'neutral'], dtype=object),\n",
       " array([1508,   54, 1297]))"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df['fsp_preds'], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "050cbe93-765c-4b30-bd7a-c8d293b99dff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       agree       0.14      0.91      0.25       238\n",
      "    disagree       0.04      0.22      0.06         9\n",
      "     neutral       0.98      0.49      0.65      2612\n",
      "\n",
      "    accuracy                           0.52      2859\n",
      "   macro avg       0.39      0.54      0.32      2859\n",
      "weighted avg       0.91      0.52      0.62      2859\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(df['stance'], df['fsp_preds'])\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b658afe0-4555-496c-b244-b00039433330",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3(c). Context + FSP + Reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "940202db-ae18-42ca-9f75-2061b4281e44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create an example template\n",
    "\n",
    "example_and_reason_template = '''\n",
    "event: {event}\n",
    "statement: {statement}\n",
    "stance: {stance}\n",
    "reason: {reason}\n",
    "'''\n",
    "\n",
    "example_and_reason_prompt = PromptTemplate(\n",
    "    input_variables=[\"event\",\"statement\", \"stance\", \"reason\"],\n",
    "    template=example_and_reason_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "32e90a11-7697-4ee8-abd1-7dedbc3c0f47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Give some examples\n",
    "\n",
    "examples = [\n",
    "    {'event':\"Putin has gone missing\",\n",
    "     'statement':\"Putin reappears on TV amid claims he is unwell and under threat of coup http://t.co/YZln23EUx1 http://t.co/ZsAnBa5gz3\",\n",
    "     'stance': 'DISAGREE',\n",
    "     'reason': \"the statement disagress with Putin having dissapeared as he was on TV and gives a reason for Putin's absence.\"\n",
    "    },\n",
    "    {'event':\"Michael Essien contracted Ebola\",\n",
    "     'statement': '''What? \"@FootballcomEN: Unconfirmed reports claim that Michael Essien has contracted Ebola. http://t.co/GsEizhwaV7\"''',\n",
    "     'stance': 'NEUTRAL',\n",
    "     'reason': \"the statement is neutral toward wether Michael Essen contracted Ebola, as it mostly just repeats the original post from @FootballcomEN askign for more information.\"\n",
    "    },\n",
    "    {'event':\"A Germanwings plane crashed\",\n",
    "     'statement': '''@thatjohn @planefinder why would they say urgence in lieu of mayday which is standard ?''',\n",
    "     'stance': 'NEUTRAL',\n",
    "     'reason': \"the statement is neutral toward wether a germanwings plane crashed as it is only asking for clarifiying details about what has been reported.\"\n",
    "    },\n",
    "    {'event':\"There is a hostage situation in Sydney\",\n",
    "     'statement': '''@KEEMSTARx dick head it's not confirmed its Jihadist extremists. Don't speculate''',\n",
    "     'stance': 'NEUTRAL',\n",
    "     'reason': \"the statement is neutral toward wether there is a hostage siutation happening in Sydney as it is admonishing someone for speculating on a detail of the situation.\"\n",
    "    },\n",
    "    {'event':\"singer Prince will play a secret show in Toronto\",\n",
    "     'statement': '''OMG. #Prince rumoured to be performing in Toronto today. Exciting!''',\n",
    "     'stance': 'AGREE',\n",
    "     'reason': 'The statement agrees with singer Prince performing a show in Toronto, as it expresses excitment at the singer performing.'\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "58c0a06d-0604-445e-89b3-7807b6a60685",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prefix = \"\"\"\n",
    "The following are examples of the stance of a social media comment towards an event happening. Each example has the stance that indicates wether the comment agrees that the event is happening and the reason for why that stance was given for that statement.\n",
    "\"\"\"\n",
    "\n",
    "suffix = '''\n",
    "Now, classify each of the statements as to wether they \"AGREE\", \"DISAGREE\", or are \"NEUTRAL\" toward event \"{event}\" happening and your reasoning. Only return the classification label for all of the statements and the reasoning for each classification label in the form of:\n",
    "[label, label, ...], [reason, reason, ...]\n",
    "\n",
    "statements:\n",
    "{statements}\n",
    "'''\n",
    "\n",
    "few_shot_and_reason_prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_and_reason_prompt,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"event\", \"statements\"],\n",
    "    example_separator=\"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13aabfb6-da64-4d33-b501-d24e5e0c41e8",
   "metadata": {},
   "source": [
    "### Run an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "11e71c23-d2eb-467c-8dfa-9b99521c0495",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "event = df['event'][0]\n",
    "statements = df[df['event'] == event]['full_text'][0:20].tolist()\n",
    "y_true = df[df['event'] == event]['stance'][0:20].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "0b2606a6-dc35-45a4-aa4c-a9d0cdb733e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-4\",\n",
    "  messages = [{\"role\":\"user\",\"content\":few_shot_and_reason_prompt.format(event = event, statements=statements)}],\n",
    "  stop=None)\n",
    "\n",
    "results = response.choices[0].message['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "711e81c2-c074-4a35-8c93-a0b2575f8bb4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       agree       0.25      1.00      0.40         5\n",
      "    disagree       0.00      0.00      0.00         1\n",
      "     neutral       0.00      0.00      0.00        14\n",
      "\n",
      "    accuracy                           0.25        20\n",
      "   macro avg       0.08      0.33      0.13        20\n",
      "weighted avg       0.06      0.25      0.10        20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Remove trailing newline and split into two strings  \n",
    "stances_str, statements_str = re.split('], \\[|\\], \\n\\[|\\],\\n\\n\\[|\\], \\n\\n\\[|\\],\\n\\[', results.strip())\n",
    "  \n",
    "# Add brackets to make them valid list strings  \n",
    "stances_str = stances_str + ']'  \n",
    "statements_str = '[' + statements_str  \n",
    "  \n",
    "# Convert strings to lists  \n",
    "y_pred = [str.lower(i) for  i in ast.literal_eval(stances_str)]\n",
    "#reasons = ast.literal_eval(statements_str)  \n",
    "\n",
    "y_true = [str.lower(i) for i in y_true]\n",
    "\n",
    "# generating the classification report\n",
    "report = classification_report(y_true, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e47e691-8ef2-4cae-adf7-4e0211f04e5a",
   "metadata": {},
   "source": [
    "### Run on all Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "2d04c4ca-471d-46a1-896b-c26d61ba93e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event: Russian President Putin has gone missing, has 46 statements\n",
      "event: there was a shooting event at Charlie Hebdo in Paris, has 711 statements\n",
      "event: singer Prince will play a secret show in Toronto, has 78 statements\n",
      "event: There is unrest in Ferguson, Missouri, has 694 statements\n",
      "event: A Germanwings plane crashed, has 209 statements\n",
      "event: There was a shooting event in Ottawa, has 482 statements\n",
      "event: There is a hostage situation in Sydney, has 623 statements\n",
      "event: Michael Essien contracted Ebola, has 16 statements\n"
     ]
    }
   ],
   "source": [
    "df['fsp_reason_preds'] =''\n",
    "num_statements_per_prompt = 20\n",
    "\n",
    "for event in df['event'].unique():\n",
    "    all_statements = df[df['event'] == event]['full_text'].tolist()\n",
    "    preds = []\n",
    "    print(\"event: {}, has {} statements\".format(event, len(all_statements)))\n",
    "    for statements in [all_statements[idx:idx+num_statements_per_prompt] for idx in range(0, len(all_statements), num_statements_per_prompt)]:\n",
    "\n",
    "        response = openai.ChatCompletion.create(\n",
    "          model=\"gpt-4\",\n",
    "          messages = [{\"role\":\"user\",\"content\":few_shot_and_reason_prompt.format(event = event, statements=statements)}],\n",
    "          stop=None)\n",
    "        results = response.choices[0].message['content']\n",
    "        # Remove trailing newline and split into two strings  \n",
    "        stances_str, statements_str = re.split('], \\[|\\], \\n\\[|\\],\\n\\n\\[|\\], \\n\\n\\[|\\],\\n\\[', results.strip())\n",
    "\n",
    "        # Add brackets to make them valid list strings  \n",
    "        stances_str = stances_str + ']'  \n",
    "        statements_str = '[' + statements_str  \n",
    "\n",
    "        # Convert strings to lists  \n",
    "        preds += [str.lower(i) for  i in ast.literal_eval(stances_str)][:num_statements_per_prompt]\n",
    "        #reasons = ast.literal_eval(statements_str)  \n",
    "        \n",
    "    df.loc[df['event'] == event, 'fsp_reason_preds'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "97157b49-ef39-4c4d-9e1f-782eeafd3d9a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['agree', 'disagree', 'neutral'], dtype=object),\n",
       " array([1491,   52, 1316]))"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df['fsp_reason_preds'], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "e44d2f6c-78b5-4740-9415-65c460ee3220",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       agree       0.14      0.86      0.24       238\n",
      "    disagree       0.04      0.22      0.07         9\n",
      "     neutral       0.97      0.49      0.65      2612\n",
      "\n",
      "    accuracy                           0.52      2859\n",
      "   macro avg       0.38      0.52      0.32      2859\n",
      "weighted avg       0.90      0.52      0.62      2859\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(df['stance'], df['fsp_reason_preds'])\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "d03aa11f-e001-4907-bd66-e989a653c0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"phemerumors_gpt4_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118b6e4f-2a7b-41db-82e2-fbb97d342214",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
