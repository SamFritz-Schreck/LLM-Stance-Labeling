{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b37c7bb-c037-4504-a2e2-4010b3726ac8",
   "metadata": {},
   "source": [
    "# Stance Classification for SemEval2016\n",
    "- read in the data and pre-process\n",
    "- set up an LLM\n",
    "- Investigate different prompting schemes\n",
    "    - just context\n",
    "    - context + few-shot learning\n",
    "    - content + few-shot learning + reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b436af4-75ff-4598-a9e3-70e746e1f99d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.33.1-py3-none-any.whl (7.6 MB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.9.0)\n",
      "Collecting huggingface-hub<1.0,>=0.15.1 (from transformers)\n",
      "  Using cached huggingface_hub-0.17.1-py3-none-any.whl (294 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Using cached regex-2023.8.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (771 kB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.30.0)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
      "  Using cached tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "Collecting safetensors>=0.3.1 (from transformers)\n",
      "  Using cached safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n",
      "Installing collected packages: tokenizers, safetensors, regex, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.17.1 regex-2023.8.8 safetensors-0.3.3 tokenizers-0.13.3 transformers-4.33.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: langchain in /home/jovyan/.local/lib/python3.10/site-packages (0.0.158)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.13)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.4)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.2)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /home/jovyan/.local/lib/python3.10/site-packages (from langchain) (0.5.7)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.4)\n",
      "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
      "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /home/jovyan/.local/lib/python3.10/site-packages (from langchain) (1.2.4)\n",
      "Requirement already satisfied: pydantic<2,>=1 in /home/jovyan/.local/lib/python3.10/site-packages (from langchain) (1.10.8)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.30.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/jovyan/.local/lib/python3.10/site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: tqdm>=4.48.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.65.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /home/jovyan/.local/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.19.0)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /home/jovyan/.local/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (1.5.1)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in /home/jovyan/.local/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.8.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1->langchain) (4.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.5.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.3->langchain) (2.0.2)\n",
      "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Collecting accelerate\n",
      "  Using cached accelerate-0.22.0-py3-none-any.whl (251 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1+cu118)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.0.0)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (3.25.0)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (15.0.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Installing collected packages: accelerate\n",
      "Successfully installed accelerate-0.22.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Collecting einops\n",
      "  Using cached einops-0.6.1-py3-none-any.whl (42 kB)\n",
      "Installing collected packages: einops\n",
      "Successfully installed einops-0.6.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Collecting deepspeed\n",
      "  Using cached deepspeed-0.10.3-py3-none-any.whl\n",
      "Collecting hjson (from deepspeed)\n",
      "  Using cached hjson-3.1.0-py3-none-any.whl (54 kB)\n",
      "Collecting ninja (from deepspeed)\n",
      "  Using cached ninja-1.11.1-py2.py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (145 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deepspeed) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from deepspeed) (23.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from deepspeed) (5.9.5)\n",
      "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from deepspeed) (9.0.0)\n",
      "Requirement already satisfied: pydantic<2.0.0 in /home/jovyan/.local/lib/python3.10/site-packages (from deepspeed) (1.10.8)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from deepspeed) (2.0.1+cu118)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from deepspeed) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.0.0->deepspeed) (4.5.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (3.9.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (3.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (2.0.0)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->deepspeed) (3.25.0)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->deepspeed) (15.0.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->deepspeed) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->deepspeed) (1.3.0)\n",
      "Installing collected packages: ninja, hjson, deepspeed\n",
      "Successfully installed deepspeed-0.10.3 hjson-3.1.0 ninja-1.11.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Package installations to work on WIRE\n",
    "\n",
    "! pip install transformers\n",
    "! pip install langchain\n",
    "! pip install accelerate\n",
    "! pip install einops\n",
    "! pip install deepspeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86e77263-062c-44bc-8ace-6cf3a638e014",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-13 13:08:32.295215: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-09-13 13:08:32.347494: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-13 13:08:33.166602: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-09-13 13:08:34,786] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "import os, re, pandas as pd, numpy as np, ast, json\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm  \n",
    "\n",
    "import torch\n",
    "from langchain import PromptTemplate, FewShotPromptTemplate, HuggingFacePipeline, LLMChain\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "import deepspeed\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5057d3-9986-42e2-91f9-ccb0a8a782e5",
   "metadata": {},
   "source": [
    "# 1. Import and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab8789ed-ab80-429d-a03e-6c07ac91a9d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file = os.path.join(\"semeval\",\"data_merged.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdaa0228-553d-4169-a510-a8a974955d6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e771931-ba00-487c-8c7a-dc68a435f86f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>event</th>\n",
       "      <th>full_text</th>\n",
       "      <th>stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>Atheism</td>\n",
       "      <td>dear lord thank u for all of ur blessings forg...</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102</td>\n",
       "      <td>Atheism</td>\n",
       "      <td>Blessed are the peacemakers, for they shall be...</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103</td>\n",
       "      <td>Atheism</td>\n",
       "      <td>I am not conformed to this world. I am transfo...</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104</td>\n",
       "      <td>Atheism</td>\n",
       "      <td>Salah should be prayed with #focus and #unders...</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105</td>\n",
       "      <td>Atheism</td>\n",
       "      <td>And stay in your houses and do not display you...</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id    event                                          full_text   \n",
       "0       101  Atheism  dear lord thank u for all of ur blessings forg...  \\\n",
       "1       102  Atheism  Blessed are the peacemakers, for they shall be...   \n",
       "2       103  Atheism  I am not conformed to this world. I am transfo...   \n",
       "3       104  Atheism  Salah should be prayed with #focus and #unders...   \n",
       "4       105  Atheism  And stay in your houses and do not display you...   \n",
       "\n",
       "     stance  \n",
       "0  disagree  \n",
       "1  disagree  \n",
       "2  disagree  \n",
       "3  disagree  \n",
       "4  disagree  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6ceb2cd-e7cc-4c58-aa8e-1b42f6f7e3ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2814, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a182cfb3-9a8d-4e44-8570-eb37c9a418a0",
   "metadata": {},
   "source": [
    "# 2. Connect to LLM\n",
    "- for standing up a smaller huggingface model\n",
    "```python\n",
    "llm = HuggingFacePipeline.from_model_id(model_id=\"declare-lab/flan-alpaca-gpt4-xl\", task = 'text2text-generation', device=0,\n",
    "                                      model_kwargs={\"max_length\":500, \"do_sample\":False})\n",
    "```\n",
    "- for a mid-sized, more modern, huggingface model. You can use accelerate and chance ``` device = \"auto\"``` to use multiple GPUs\n",
    "```python\n",
    "model = \"tiiuae/falcon-7b-instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "    device_map=0,\n",
    "    max_length=200,\n",
    "    do_sample=False,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=pipe)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a845955d-162c-4531-a774-231a465372f6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6314477e36324804a30be8d093f141b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = \"declare-lab/flan-alpaca-gpt4-xl\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    trust_remote_code=True,\n",
    "    device_map=0,\n",
    "    max_length=1000,\n",
    "    do_sample=False,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403fdd62-677d-467f-b0d6-ef232fc9ca70",
   "metadata": {},
   "source": [
    "look at a few examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "750d3b59-d13a-45ce-8f09-ee1680c395a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AGAINST'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = '''What is the stance of of the following social media post toward the U.S. Army. Give the stance as either 'FOR', \"AGAINST', or 'NEUTRAL'. Only return the stance:\n",
    "\"@vondeveen If the Army wants to actually recruit people, maybe stop breaking people and actually prosecute sexual assualt #nomorewar.\"\n",
    "'''\n",
    "llm(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8539ac1f-1155-4e53-9837-2f311a898965",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NEUTRAL'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = '''What is the stance of of the following social media post toward the U.S. Army. Give the stance as either 'FOR', \"AGAINST', or 'NEUTRAL'. Only return the stance:\n",
    "\"@artfulask I have never seen a pink-eared duck before. #Army\"\n",
    "'''\n",
    "llm(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "283a5080-d9f4-4e95-81be-da898da57990",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FOR'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = '''What is the stance of of the following social media post toward the U.S. Army. Give the stance as either 'FOR', \"AGAINST', or 'NEUTRAL'. Only return the stance:\n",
    "\"I think the @Army helped me become disciplined. I would have surely flunked out of college chasing tail if I didn't get some discipline there. #SFL\"\n",
    "'''\n",
    "llm(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c99f07-4c5d-49a7-bac9-36a3399c2927",
   "metadata": {},
   "source": [
    "# 3. Prompt Engineering for Stance Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e692217e-d8cb-44c8-ab54-21c3c076d6ee",
   "metadata": {},
   "source": [
    "## 3(a). Task-only prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f5cefeed-4bcb-48a9-815f-7e02011e417a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# task-only prompt\n",
    "\n",
    "task_template = '''\n",
    "Classify the sentiment of the statement as 'POSITIVE', 'NEGATIVE', or 'NEUTRAL'. Only return the sentiment label for the statement, and no other text.\n",
    "\n",
    "statement: {statement}\n",
    "'''\n",
    "\n",
    "task_prompt = PromptTemplate(\n",
    "    input_variables=[\"statement\"],\n",
    "    template=task_template\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0486f1e-b948-4cf8-921b-756139394b11",
   "metadata": {},
   "source": [
    "### Run an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a23f26eb-0ade-4a4e-9a99-5f91c9075438",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a sample for all examples\n",
    "\n",
    "random_sample_df = df.sample(100)\n",
    "y_true = random_sample_df['stance'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d5a3a1f4-aac6-48be-8364-6e190ed49366",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(prompt=task_prompt, llm=llm)\n",
    "\n",
    "results=[]\n",
    "for row in random_sample_df.iterrows():\n",
    "    results.append(llm_chain.run(event=row[1]['event'], statement=row[1]['full_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9e436eb7-c2f2-41cd-b484-cc9160c4b1f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       agree       0.35      0.51      0.42        35\n",
      "    disagree       0.52      0.39      0.44        41\n",
      "     neutral       0.17      0.12      0.14        24\n",
      "\n",
      "    accuracy                           0.37       100\n",
      "   macro avg       0.35      0.34      0.34       100\n",
      "weighted avg       0.38      0.37      0.36       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# converting to given labels for comparison\n",
    "\n",
    "y_true = [str.lower(i) for i in y_true]\n",
    "y_pred = []  \n",
    "  \n",
    "for word in results:  \n",
    "    lower_word = word.lower()  \n",
    "    if 'positive' in lower_word:  \n",
    "        y_pred.append('agree')  \n",
    "    elif 'negative' in lower_word:  \n",
    "        y_pred.append('disagree')  \n",
    "    elif 'neutral' in lower_word:  \n",
    "        y_pred.append('neutral')  \n",
    "    else:  \n",
    "        y_pred.append('neutral')\n",
    "\n",
    "# generating the classification report\n",
    "report = classification_report(y_true, y_pred)\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477aed9a-deec-40f1-85a3-fda877fb86c3",
   "metadata": {},
   "source": [
    "### Run on all Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2a3aa074-0261-4e3d-a57c-7313d9679bc4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "2814it [07:41,  6.10it/s]\n"
     ]
    }
   ],
   "source": [
    "# Running across the whole dataset\n",
    "\n",
    "results = []\n",
    "for index, row in tqdm(df.iterrows()):\n",
    "    results.append(llm_chain.run(event=row['event'], statement=row['full_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "63130b8a-c103-4df4-bb91-9d70213947fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['NEGATIVE', 'NEUTRAL', 'POSITIVE'], dtype='<U8'),\n",
       " array([1092,  400, 1322]))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(results, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c4cf24d7-ca26-4735-9a57-9cf826e0a286",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = []  \n",
    "  \n",
    "for word in results:  \n",
    "    lower_word = word.lower()  \n",
    "    if 'positive' in lower_word:  \n",
    "        y_pred.append('agree')  \n",
    "    elif 'negative' in lower_word:  \n",
    "        y_pred.append('disagree')  \n",
    "    elif 'neutral' in lower_word:  \n",
    "        y_pred.append('neutral')  \n",
    "    else:  \n",
    "        y_pred.append('neutral')\n",
    "        \n",
    "df['task_preds'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e334043f-4a5f-4a40-813f-0021570ae054",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['agree', 'disagree', 'neutral'], dtype=object),\n",
       " array([1322, 1092,  400]))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df['task_preds'], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "906f54ca-301b-442e-9c0e-776598a98063",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       agree       0.29      0.52      0.37       731\n",
      "    disagree       0.54      0.44      0.49      1342\n",
      "     neutral       0.31      0.17      0.22       741\n",
      "\n",
      "    accuracy                           0.39      2814\n",
      "   macro avg       0.38      0.38      0.36      2814\n",
      "weighted avg       0.42      0.39      0.39      2814\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(df['stance'], df['task_preds'])\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753eac3e-fba1-4615-bc84-6b576814fd28",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3(b). Context prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f23b18b6-82f8-4498-b9e1-5dbfb4662996",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# context prompt\n",
    "\n",
    "context_template = '''\n",
    "The following statement is a social media post expressing an opinion about an entity. Classify the sentiment of the statement only toward the entity below as 'NEGATIVE', 'POSITIVE', or 'NEUTRAL'. Only return the sentiment label for the statement toward the entity, and no other text.\n",
    "\n",
    "entity: {event}\n",
    "statement: {statement}\n",
    "'''\n",
    "\n",
    "context_prompt = PromptTemplate(\n",
    "    input_variables=[\"event\",\"statement\"],\n",
    "    template=context_template\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76cda91-c949-4268-bfc8-39d3999eef46",
   "metadata": {},
   "source": [
    "### Run an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "70668cf6-2cb0-45bf-a14b-0541630a819c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "llm_chain = LLMChain(prompt=context_prompt, llm=llm)\n",
    "\n",
    "results=[]\n",
    "for row in random_sample_df.iterrows():\n",
    "    results.append(llm_chain.run(event=row[1]['event'], statement=row[1]['full_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "88aefc12-a867-4975-9340-46ec79d49122",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       agree       0.47      0.69      0.56        35\n",
      "    disagree       0.63      0.41      0.50        41\n",
      "     neutral       0.27      0.25      0.26        24\n",
      "\n",
      "    accuracy                           0.47       100\n",
      "   macro avg       0.46      0.45      0.44       100\n",
      "weighted avg       0.49      0.47      0.46       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# converting to given labels for comparison\n",
    "\n",
    "y_true = [str.lower(i) for i in y_true]\n",
    "y_pred = []  \n",
    "  \n",
    "for word in results:  \n",
    "    lower_word = word.lower()  \n",
    "    if 'positive' in lower_word:  \n",
    "        y_pred.append('agree')  \n",
    "    elif 'negative' in lower_word:  \n",
    "        y_pred.append('disagree')  \n",
    "    elif 'neutral' in lower_word:  \n",
    "        y_pred.append('neutral')  \n",
    "    else:  \n",
    "        y_pred.append('neutral')\n",
    "\n",
    "# generating the classification report  \n",
    "report = classification_report(y_true, y_pred)  \n",
    "  \n",
    "print(report)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d122fe57-c6a0-4f9f-88f2-ab3b033d4969",
   "metadata": {},
   "source": [
    "### Run on all Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "20dbad2c-32b1-4d2d-a7be-ed3833768633",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "2814it [07:44,  6.05it/s]\n"
     ]
    }
   ],
   "source": [
    "# Running across the whole dataset\n",
    "\n",
    "results = []\n",
    "for index, row in tqdm(df.iterrows()):\n",
    "    results.append(llm_chain.run(event=row['event'], statement=row['full_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "cf183a8f-03b9-4145-8b8b-bd004fc88006",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['NEGATIVE', 'NEUTRAL', 'POSITIVE'], dtype='<U8'),\n",
       " array([1004,  620, 1190]))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(results, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0da70805-b9b7-4840-9dbb-a31897733630",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = []  \n",
    "  \n",
    "for word in results:  \n",
    "    lower_word = word.lower()  \n",
    "    if 'positive' in lower_word:  \n",
    "        y_pred.append('agree')  \n",
    "    elif 'negative' in lower_word:  \n",
    "        y_pred.append('disagree')  \n",
    "    elif 'neutral' in lower_word:  \n",
    "        y_pred.append('neutral')  \n",
    "    else:  \n",
    "        y_pred.append('neutral')\n",
    "        \n",
    "df['context_preds'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4a9b196d-2158-40eb-9adb-84c62c5dcd53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['agree', 'disagree', 'neutral'], dtype=object),\n",
       " array([1190, 1004,  620]))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df['context_preds'], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e999ba12-0fa0-4204-bb0a-84376a5ab041",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       agree       0.40      0.65      0.49       731\n",
      "    disagree       0.67      0.50      0.57      1342\n",
      "     neutral       0.31      0.26      0.29       741\n",
      "\n",
      "    accuracy                           0.48      2814\n",
      "   macro avg       0.46      0.47      0.45      2814\n",
      "weighted avg       0.50      0.48      0.48      2814\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(df['stance'], df['context_preds'])\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a8755d-d895-49b1-bc13-1965215392fd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3(c). Context + FSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0407c388-7977-443d-beba-03c0faa2ab64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create an example template\n",
    "\n",
    "example_template = '''\n",
    "entity: {entity}\n",
    "statement: {statement}\n",
    "sentiment: {sentiment}\n",
    "'''\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"entity\",\"statement\", \"sentiment\"],\n",
    "    template=example_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1cfae949-c846-4f0f-b31a-f84d30e54be9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Give some examples\n",
    "\n",
    "examples = [\n",
    "    {'entity':\"Atheism\",\n",
    "     'statement':\"Leaving Christianity enables you to love the people you once rejected. #freethinker #Christianity #SemST\",\n",
    "     'sentiment': 'POSITIVE'},\n",
    "    {'entity':\"Climate Change is a Real Concern\",\n",
    "     'statement':\"@AlharbiF I'll bomb anything I can get my hands on, especially if THEY aren't christian. #graham2016 #GOP #SemST\",\n",
    "     'sentiment': 'NEUTRAL'},\n",
    "    {'entity':\"Feminist Movement\",\n",
    "     'statement':\"Always a delight to see chest-drumming alpha males hiss and scuttle backwards up the wall when a feminist enters the room. #manly #SemST\",\n",
    "     'sentiment': 'POSITIVE'},\n",
    "    {'entity':\"Hillary Clinton\",\n",
    "     'statement':\"Would you wanna be in a long term relationship with some bitch that hides her emails, & lies to your face? Then #Dontvote #SemST\",\n",
    "     'sentiment': 'NEGATIVE'},\n",
    "    {'entity':\"Legalization of Abortion\",\n",
    "     'statement':\"@k_yoder That lady needs help, mental illness is a serious issue. #SemST\",\n",
    "     'sentiment': 'NEUTRAL'},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6ec3f4a3-be9d-46df-bed7-8b2afa937000",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prefix = \"\"\"\n",
    "The following statements are social media posts expressing opinions about an entities. Each statement can have a sentiment of 'POSITIVE', 'NEGATIVE', or 'NEUTRAL' toward their associated entity.\n",
    "\"\"\"\n",
    "\n",
    "suffix = '''\n",
    "Now, classify the sentiment of following statement toward the following entity as 'POSITIVE', 'NEGATIVE', or 'NEUTRAL'. Only return the sentiment label for the statement toward the entity, and no other text.\n",
    "\n",
    "entity: {event}\n",
    "statement: {statement}\n",
    "'''\n",
    "\n",
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"event\", \"statement\"],\n",
    "    example_separator=\"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6c9f10-3438-446e-9812-f4d1a1e70c1b",
   "metadata": {},
   "source": [
    "### Run an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "14e63860-b15e-4b0f-89be-16ef75f83c3e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "llm_chain = LLMChain(prompt=few_shot_prompt, llm=llm)\n",
    "\n",
    "results=[]\n",
    "for row in random_sample_df.iterrows():\n",
    "    results.append(llm_chain.run(event=row[1]['event'], statement=row[1]['full_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "48e8de6c-a692-4a13-a94a-a94ce0404006",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       agree       0.46      0.66      0.54        35\n",
      "    disagree       0.65      0.41      0.51        41\n",
      "     neutral       0.38      0.38      0.38        24\n",
      "\n",
      "    accuracy                           0.49       100\n",
      "   macro avg       0.50      0.48      0.47       100\n",
      "weighted avg       0.52      0.49      0.49       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# converting to given labels for comparison\n",
    "\n",
    "y_true = [str.lower(i) for i in y_true]\n",
    "y_pred = []  \n",
    "  \n",
    "for word in results:  \n",
    "    lower_word = word.lower()  \n",
    "    if 'positive' in lower_word:  \n",
    "        y_pred.append('agree')  \n",
    "    elif 'negative' in lower_word:  \n",
    "        y_pred.append('disagree')  \n",
    "    elif 'neutral' in lower_word:  \n",
    "        y_pred.append('neutral')  \n",
    "    else:  \n",
    "        y_pred.append('neutral')\n",
    "\n",
    "# generating the classification report  \n",
    "report = classification_report(y_true, y_pred)  \n",
    "  \n",
    "print(report)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0622d58d-9df3-4a17-8d22-244df05436de",
   "metadata": {},
   "source": [
    "### Run on all Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "bc5169c2-4b07-4237-baf3-af889bdf11e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "2814it [10:23,  4.51it/s]\n"
     ]
    }
   ],
   "source": [
    "# Running across the whole dataset\n",
    "\n",
    "results = []\n",
    "for index, row in tqdm(df.iterrows()):\n",
    "    results.append(llm_chain.run(event=row['event'], statement=row['full_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "beda45b7-f275-4fa3-b59d-9009b51d6682",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['NEGATIVE', 'NEUTRAL', 'POSITIVE'], dtype='<U8'),\n",
       " array([1043,  594, 1177]))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(results, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7dc5c63a-b901-4541-81dd-e69985f36460",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = []  \n",
    "  \n",
    "for word in results:  \n",
    "    lower_word = word.lower()  \n",
    "    if 'positive' in lower_word:  \n",
    "        y_pred.append('agree')  \n",
    "    elif 'negative' in lower_word:  \n",
    "        y_pred.append('disagree')  \n",
    "    elif 'neutral' in lower_word:  \n",
    "        y_pred.append('neutral')  \n",
    "    else:  \n",
    "        y_pred.append('neutral')\n",
    "        \n",
    "df['fsp_preds'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a1521a68-6865-496e-87e1-5990887725a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['agree', 'disagree', 'neutral'], dtype=object),\n",
       " array([1177, 1043,  594]))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df['fsp_preds'], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "050cbe93-765c-4b30-bd7a-c8d293b99dff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       agree       0.41      0.66      0.50       731\n",
      "    disagree       0.69      0.54      0.60      1342\n",
      "     neutral       0.45      0.36      0.40       741\n",
      "\n",
      "    accuracy                           0.52      2814\n",
      "   macro avg       0.52      0.52      0.50      2814\n",
      "weighted avg       0.55      0.52      0.52      2814\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(df['stance'], df['fsp_preds'])\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b658afe0-4555-496c-b244-b00039433330",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3(d). Context + FSP + Reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "940202db-ae18-42ca-9f75-2061b4281e44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create an example template\n",
    "\n",
    "example_and_reason_template = '''\n",
    "entity: {entity}\n",
    "statement: {statement}\n",
    "sentiment: {sentiment}\n",
    "reason: {reason}\n",
    "'''\n",
    "\n",
    "example_and_reason_prompt = PromptTemplate(\n",
    "    input_variables=[\"entity\",\"statement\", \"sentiment\", \"reason\"],\n",
    "    template=example_and_reason_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "32e90a11-7697-4ee8-abd1-7dedbc3c0f47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Give some examples\n",
    "\n",
    "examples = [\n",
    "    {'entity':\"Atheism\",\n",
    "     'statement':'''Leaving Christianity enables you to love the people you once rejected. #freethinker #Christianity #SemST''',\n",
    "     'sentiment': 'POSITIVE',\n",
    "     'reason': \"The statement is positive toward atheism as it claims leaving a religion like christianity makes one more loving.\"\n",
    "    },\n",
    "    {'entity':\"Climate Change is a Real Concern\",\n",
    "     'statement':'''@AlharbiF I'll bomb anything I can get my hands on, especially if THEY aren't christian. #graham2016 #GOP #SemST''',\n",
    "     'sentiment': 'NEUTRAL',\n",
    "     'reason': \"The statement does not explicity reference climate change and it is not clear who the author would bomb, so it is neutral toward climate change.\"\n",
    "    },\n",
    "    {'entity':\"Feminist Movement\",\n",
    "     'statement':'''Always a delight to see chest-drumming alpha males hiss and scuttle backwards up the wall when a feminist enters the room. #manly #SemST''',\n",
    "     'sentiment': 'POSITIVE',\n",
    "     'reason': \"The statement is positive towards the feminist movement as it makes fun of alpha males, who are typically seen as being against feminism.\"\n",
    "    },\n",
    "    {'entity':\"Hillary Clinton\",\n",
    "     'statement':'''Would you wanna be in a long term relationship with some bitch that hides her emails, & lies to your face? Then #Dontvote #SemST''',\n",
    "     'sentiment': 'NEGATIVE',\n",
    "     'reason': \"The statement is negative toward Hillary Clinton as it calles her a bitch and claims she does bad things like hides emails and lies.\"\n",
    "    },\n",
    "    {'entity':\"Legalization of Abortion\",\n",
    "     'statement':'''@k_yoder That lady needs help, mental illness is a serious issue. #SemST''',\n",
    "     'sentiment': 'NEUTRAL',\n",
    "     'reason': \"the statement is neutral toward legalization of abortion as it does not talk about abortion and its not clear if the mentioned lady is related to abortion at all.\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "58c0a06d-0604-445e-89b3-7807b6a60685",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prefix = \"\"\"\n",
    "The following statements are social media posts expressing opinions about an entities. The sentiment of each statement can be 'POSITIVE', 'NEGATIVE', or 'NEUTRAL' toward their associated entity. Each statement has a reason for why the senitment toward the entity is classified as it is.\n",
    "\"\"\"\n",
    "\n",
    "suffix = '''\n",
    "Now, classify the sentiment of the following statement toward the entity below as 'POSITIVE', NEGATIVE', or 'NEUTRAL' and give your reasoning. Only return the sentiment label for the statement toward the entity and the reason for the sentiment label in the form of: 'sentiment: SENTIMENT, reason: REASON'\n",
    "\n",
    "entity: {event}\n",
    "statement: {statement}\n",
    "'''\n",
    "\n",
    "few_shot_and_reason_prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_and_reason_prompt,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"event\", \"statement\"],\n",
    "    example_separator=\"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13aabfb6-da64-4d33-b501-d24e5e0c41e8",
   "metadata": {},
   "source": [
    "### Run an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0b2606a6-dc35-45a4-aa4c-a9d0cdb733e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "llm_chain = LLMChain(prompt=few_shot_and_reason_prompt, llm=llm)\n",
    "\n",
    "results=[]\n",
    "for row in random_sample_df.iterrows():\n",
    "    results.append(llm_chain.run(event=row[1]['event'], statement=row[1]['full_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "711e81c2-c074-4a35-8c93-a0b2575f8bb4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       agree       0.50      0.86      0.63        35\n",
      "    disagree       0.73      0.59      0.65        41\n",
      "     neutral       0.86      0.25      0.39        24\n",
      "\n",
      "    accuracy                           0.60       100\n",
      "   macro avg       0.69      0.56      0.56       100\n",
      "weighted avg       0.68      0.60      0.58       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = []  \n",
    "reasons = []  \n",
    "  \n",
    "for result in results:  \n",
    "    split_result = result.split('reason:')  \n",
    "    if len(split_result) == 2:  \n",
    "        # Extract stance and reason, remove leading/trailing whitespace and convert stance to lowercase  \n",
    "        stance, reason = split_result\n",
    "        stance = stance.replace('sentiment:', '').replace(',', '').strip().lower()\n",
    "        reason = reason.strip()\n",
    "        reasons.append(reason)\n",
    "    else:\n",
    "        # model did not give a reason\n",
    "        stance = split_result[0]\n",
    "        stance = stance.replace('sentiment:', '').replace(',', '').strip().lower()\n",
    "        reasons.append('')\n",
    "    if 'positive' in stance:  \n",
    "        y_pred.append('agree')  \n",
    "    elif 'negative' in stance:  \n",
    "        y_pred.append('disagree')  \n",
    "    elif 'neutral' in stance:  \n",
    "        y_pred.append('neutral')\n",
    "    else:  \n",
    "        y_pred.append('neutral')\n",
    "\n",
    "y_true = [str.lower(i) for i in y_true]\n",
    "\n",
    "# generating the classification report\n",
    "report = classification_report(y_true, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e47e691-8ef2-4cae-adf7-4e0211f04e5a",
   "metadata": {},
   "source": [
    "### Run on all Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2d04c4ca-471d-46a1-896b-c26d61ba93e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "2814it [39:04,  1.20it/s]\n"
     ]
    }
   ],
   "source": [
    "# Running across the whole dataset\n",
    "\n",
    "results = []\n",
    "for index, row in tqdm(df.iterrows()):\n",
    "    results.append(llm_chain.run(event=row['event'], statement=row['full_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "97157b49-ef39-4c4d-9e1f-782eeafd3d9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = []  \n",
    "reasons = []  \n",
    "  \n",
    "for result in results:  \n",
    "    split_result = result.split('reason:')  \n",
    "    if len(split_result) == 2:  \n",
    "        # Extract stance and reason, remove leading/trailing whitespace and convert stance to lowercase  \n",
    "        stance, reason = split_result\n",
    "        stance = stance.replace('sentiment:', '').replace(',', '').strip().lower()\n",
    "        reason = reason.strip()\n",
    "        reasons.append(reason)\n",
    "    else:\n",
    "        # model did not give a reason\n",
    "        stance = split_result[0]\n",
    "        stance = stance.replace('sentiment:', '').replace(',', '').strip().lower()\n",
    "        reasons.append('')\n",
    "    if 'positive' in stance:  \n",
    "        y_pred.append('agree')  \n",
    "    elif 'negative' in stance:  \n",
    "        y_pred.append('disagree')  \n",
    "    elif 'neutral' in stance:  \n",
    "        y_pred.append('neutral')\n",
    "    else:  \n",
    "        y_pred.append('neutral')\n",
    "        \n",
    "df['fsp_reason_preds'] = y_pred\n",
    "df['fsp_reason_reasons'] = reasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b02b73fb-2ec0-49f1-b0a2-baeef114f4cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['agree', 'disagree', 'neutral'], dtype=object),\n",
       " array([1470, 1145,  199]))"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df['fsp_reason_preds'], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e44d2f6c-78b5-4740-9415-65c460ee3220",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       agree       0.38      0.76      0.51       731\n",
      "    disagree       0.66      0.56      0.60      1342\n",
      "     neutral       0.62      0.17      0.26       741\n",
      "\n",
      "    accuracy                           0.51      2814\n",
      "   macro avg       0.55      0.50      0.46      2814\n",
      "weighted avg       0.58      0.51      0.49      2814\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(df['stance'], df['fsp_reason_preds'])\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d03aa11f-e001-4907-bd66-e989a653c0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"semeval_sentiment_flan-alpaca-3B_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94de7d2f-b6db-4714-8efe-f7cc1357b831",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
