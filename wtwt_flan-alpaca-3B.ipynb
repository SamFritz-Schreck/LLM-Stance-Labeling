{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b37c7bb-c037-4504-a2e2-4010b3726ac8",
   "metadata": {},
   "source": [
    "# Stance Classification for wtwt\n",
    "- read in the data and pre-process\n",
    "- set up an LLM\n",
    "- Investigate different prompting schemes\n",
    "    - just context\n",
    "    - context + few-shot learning\n",
    "    - content + few-shot learning + reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b436af4-75ff-4598-a9e3-70e746e1f99d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.33.1-py3-none-any.whl (7.6 MB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.9.0)\n",
      "Collecting huggingface-hub<1.0,>=0.15.1 (from transformers)\n",
      "  Using cached huggingface_hub-0.17.1-py3-none-any.whl (294 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Using cached regex-2023.8.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (771 kB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.30.0)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
      "  Using cached tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "Collecting safetensors>=0.3.1 (from transformers)\n",
      "  Using cached safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n",
      "Installing collected packages: tokenizers, safetensors, regex, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.17.1 regex-2023.8.8 safetensors-0.3.3 tokenizers-0.13.3 transformers-4.33.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: langchain in /home/jovyan/.local/lib/python3.10/site-packages (0.0.158)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.13)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.4)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.2)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /home/jovyan/.local/lib/python3.10/site-packages (from langchain) (0.5.7)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.4)\n",
      "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
      "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /home/jovyan/.local/lib/python3.10/site-packages (from langchain) (1.2.4)\n",
      "Requirement already satisfied: pydantic<2,>=1 in /home/jovyan/.local/lib/python3.10/site-packages (from langchain) (1.10.8)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.30.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/jovyan/.local/lib/python3.10/site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: tqdm>=4.48.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.65.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /home/jovyan/.local/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.19.0)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /home/jovyan/.local/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (1.5.1)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in /home/jovyan/.local/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.8.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1->langchain) (4.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.5.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.3->langchain) (2.0.2)\n",
      "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Collecting accelerate\n",
      "  Using cached accelerate-0.22.0-py3-none-any.whl (251 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1+cu118)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.0.0)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (3.25.0)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (15.0.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Installing collected packages: accelerate\n",
      "Successfully installed accelerate-0.22.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Collecting einops\n",
      "  Using cached einops-0.6.1-py3-none-any.whl (42 kB)\n",
      "Installing collected packages: einops\n",
      "Successfully installed einops-0.6.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Collecting deepspeed\n",
      "  Downloading deepspeed-0.10.3.tar.gz (867 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m867.3/867.3 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting hjson (from deepspeed)\n",
      "  Using cached hjson-3.1.0-py3-none-any.whl (54 kB)\n",
      "Collecting ninja (from deepspeed)\n",
      "  Using cached ninja-1.11.1-py2.py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (145 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deepspeed) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from deepspeed) (23.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from deepspeed) (5.9.5)\n",
      "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from deepspeed) (9.0.0)\n",
      "Requirement already satisfied: pydantic<2.0.0 in /home/jovyan/.local/lib/python3.10/site-packages (from deepspeed) (1.10.8)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from deepspeed) (2.0.1+cu118)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from deepspeed) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.0.0->deepspeed) (4.5.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (3.9.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (3.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (2.0.0)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->deepspeed) (3.25.0)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->deepspeed) (15.0.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->deepspeed) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->deepspeed) (1.3.0)\n",
      "Building wheels for collected packages: deepspeed\n",
      "  Building wheel for deepspeed (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for deepspeed: filename=deepspeed-0.10.3-py3-none-any.whl size=907844 sha256=80f29a77b2d210dee8b780173b263616307f3283a6bae255d6f1987e35e7461f\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/d8/8e/fe/bd6467e058672bf39888e67b763f706053f6f969fe0542423d\n",
      "Successfully built deepspeed\n",
      "Installing collected packages: ninja, hjson, deepspeed\n",
      "Successfully installed deepspeed-0.10.3 hjson-3.1.0 ninja-1.11.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Package installations to work on WIRE\n",
    "\n",
    "! pip install transformers\n",
    "! pip install langchain\n",
    "! pip install accelerate\n",
    "! pip install einops\n",
    "! pip install deepspeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86e77263-062c-44bc-8ace-6cf3a638e014",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-12 12:27:51.399661: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-12 12:27:52.235822: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-09-12 12:27:53,700] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "import os, re, pandas as pd, numpy as np, ast, json\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm  \n",
    "\n",
    "import torch\n",
    "from langchain import PromptTemplate, FewShotPromptTemplate, HuggingFacePipeline, LLMChain\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "import deepspeed\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5057d3-9986-42e2-91f9-ccb0a8a782e5",
   "metadata": {},
   "source": [
    "# 1. Import and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ab8789ed-ab80-429d-a03e-6c07ac91a9d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file = os.path.join(\"wtwt\",\"data_merged.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bdaa0228-553d-4169-a510-a8a974955d6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "badd2705-a50c-4d61-998b-6a532ca6179d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['event'] = df['event'].replace({  \n",
    "    'CVS_AET': 'CVS Health buying Aetna',  \n",
    "    'CI_ESRX': 'Cigna buying Express Scripts',  \n",
    "    'ANTM_CI': 'Anthem buying Cigna',  \n",
    "    'AET_HUM': 'Aetna buying Humana',  \n",
    "    'FOXA_DIS': 'Disney buying 21st Century Fox'  \n",
    "}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4e771931-ba00-487c-8c7a-dc68a435f86f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>stance</th>\n",
       "      <th>event</th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>971761970117357568</td>\n",
       "      <td>agree</td>\n",
       "      <td>Cigna buying Express Scripts</td>\n",
       "      <td>Cigna and ESI set to merge. Here we go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>950934259371520000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Cigna buying Express Scripts</td>\n",
       "      <td>Express Scripts Closes Acquisition Of eviCore;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>973718376496357376</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Cigna buying Express Scripts</td>\n",
       "      <td>RT @Arsyjgot7: เรื่องดีๆของวันนี้คืออัลบั้ม #E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>996772902006599680</td>\n",
       "      <td>agree</td>\n",
       "      <td>Cigna buying Express Scripts</td>\n",
       "      <td>Here's the just-released 400+ page merger prox...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>979498827966279680</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Cigna buying Express Scripts</td>\n",
       "      <td>Watch UNH CVS AET CI ESRX MOH ANTM on the $HUM...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id   stance                         event   \n",
       "0  971761970117357568    agree  Cigna buying Express Scripts  \\\n",
       "1  950934259371520000  neutral  Cigna buying Express Scripts   \n",
       "2  973718376496357376  neutral  Cigna buying Express Scripts   \n",
       "3  996772902006599680    agree  Cigna buying Express Scripts   \n",
       "4  979498827966279680  neutral  Cigna buying Express Scripts   \n",
       "\n",
       "                                           full_text  \n",
       "0          Cigna and ESI set to merge. Here we go...  \n",
       "1  Express Scripts Closes Acquisition Of eviCore;...  \n",
       "2  RT @Arsyjgot7: เรื่องดีๆของวันนี้คืออัลบั้ม #E...  \n",
       "3  Here's the just-released 400+ page merger prox...  \n",
       "4  Watch UNH CVS AET CI ESRX MOH ANTM on the $HUM...  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b6ceb2cd-e7cc-4c58-aa8e-1b42f6f7e3ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32409, 4)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a182cfb3-9a8d-4e44-8570-eb37c9a418a0",
   "metadata": {},
   "source": [
    "# 2. Connect to LLM\n",
    "- for standing up a smaller huggingface model\n",
    "```python\n",
    "llm = HuggingFacePipeline.from_model_id(model_id=\"declare-lab/flan-alpaca-gpt4-xl\", task = 'text2text-generation', device=0,\n",
    "                                      model_kwargs={\"max_length\":500, \"do_sample\":False})\n",
    "```\n",
    "- for a mid-sized, more modern, huggingface model. You can use accelerate and chance ``` device = \"auto\"``` to use multiple GPUs\n",
    "```python\n",
    "model = \"tiiuae/falcon-7b-instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "    device_map=0,\n",
    "    max_length=200,\n",
    "    do_sample=False,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=pipe)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a845955d-162c-4531-a774-231a465372f6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab7cb0a6fe11435faa6ef0acb6a0c4dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = \"declare-lab/flan-alpaca-gpt4-xl\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    trust_remote_code=True,\n",
    "    device_map=0,\n",
    "    max_length=1000,\n",
    "    do_sample=False,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403fdd62-677d-467f-b0d6-ef232fc9ca70",
   "metadata": {},
   "source": [
    "look at a few examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "750d3b59-d13a-45ce-8f09-ee1680c395a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AGAINST'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = '''What is the stance of of the following social media post toward the U.S. Army. Give the stance as either 'FOR', \"AGAINST', or 'NEUTRAL'. Only return the stance:\n",
    "\"@vondeveen If the Army wants to actually recruit people, maybe stop breaking people and actually prosecute sexual assualt #nomorewar.\"\n",
    "'''\n",
    "llm(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8539ac1f-1155-4e53-9837-2f311a898965",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NEUTRAL'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = '''What is the stance of of the following social media post toward the U.S. Army. Give the stance as either 'FOR', \"AGAINST', or 'NEUTRAL'. Only return the stance:\n",
    "\"@artfulask I have never seen a pink-eared duck before. #Army\"\n",
    "'''\n",
    "llm(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "283a5080-d9f4-4e95-81be-da898da57990",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FOR'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = '''What is the stance of of the following social media post toward the U.S. Army. Give the stance as either 'FOR', \"AGAINST', or 'NEUTRAL'. Only return the stance:\n",
    "\"I think the @Army helped me become disciplined. I would have surely flunked out of college chasing tail if I didn't get some discipline there. #SFL\"\n",
    "'''\n",
    "llm(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c99f07-4c5d-49a7-bac9-36a3399c2927",
   "metadata": {},
   "source": [
    "# 3. Prompt Engineering for Stance Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e692217e-d8cb-44c8-ab54-21c3c076d6ee",
   "metadata": {},
   "source": [
    "## 3(a). Task-only prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f5cefeed-4bcb-48a9-815f-7e02011e417a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# task-only prompt\n",
    "\n",
    "task_template = '''\n",
    "Classify the statement as to whether it is 'FOR', 'AGAINST', 'NEUTRAL', or 'UNRELATED'. Only return the classification label for the statement, and no other text.\n",
    "\n",
    "statement: {statement}\n",
    "'''\n",
    "\n",
    "task_prompt = PromptTemplate(\n",
    "    input_variables=[\"statement\"],\n",
    "    template=task_template\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0486f1e-b948-4cf8-921b-756139394b11",
   "metadata": {},
   "source": [
    "### Run an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "a23f26eb-0ade-4a4e-9a99-5f91c9075438",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "event = df['event'][0]\n",
    "statements = df[df['event'] == event]['full_text'][0:20].tolist()\n",
    "y_true = df[df['event'] == event]['stance'][0:20].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d5a3a1f4-aac6-48be-8364-6e190ed49366",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "llm_chain = LLMChain(prompt=task_prompt, llm=llm)\n",
    "\n",
    "results=[]\n",
    "for statement in statements:\n",
    "    results.append(llm_chain.run(statement=statement))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "9e436eb7-c2f2-41cd-b484-cc9160c4b1f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       agree       0.20      0.33      0.25         3\n",
      "    disagree       0.00      0.00      0.00         0\n",
      "     neutral       0.85      0.65      0.73        17\n",
      "\n",
      "    accuracy                           0.60        20\n",
      "   macro avg       0.35      0.33      0.33        20\n",
      "weighted avg       0.75      0.60      0.66        20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# converting to given labels for comparison\n",
    "\n",
    "y_true = [str.lower(i) for i in y_true]\n",
    "y_pred = []  \n",
    "  \n",
    "for word in results:  \n",
    "    lower_word = word.lower()  \n",
    "    if 'for' in lower_word:  \n",
    "        y_pred.append('agree')  \n",
    "    elif 'against' in lower_word:  \n",
    "        y_pred.append('disagree')  \n",
    "    elif 'neutral' in lower_word or 'unrelated' in lower_word:  \n",
    "        y_pred.append('neutral')  \n",
    "    else:  \n",
    "        y_pred.append('neutral')\n",
    "\n",
    "# generating the classification report\n",
    "report = classification_report(y_true, y_pred)\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477aed9a-deec-40f1-85a3-fda877fb86c3",
   "metadata": {},
   "source": [
    "### Run on all Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "2a3aa074-0261-4e3d-a57c-7313d9679bc4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "32409it [1:15:44,  7.13it/s]\n"
     ]
    }
   ],
   "source": [
    "# Running across the whole dataset\n",
    "\n",
    "results = []\n",
    "for index, row in tqdm(df.iterrows()):\n",
    "    results.append(llm_chain.run(event=row['event'], statement=row['full_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "af62c168-de1d-4b82-a8a8-f0bf5940d100",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"'AGAINST'\", \"'FOR'\", \"'FOR' and 'AGAINST'.\", \"'NEUTRAL'\",\n",
       "       \"'UNRELATED'\", 'AGAINST', 'FOR', 'NEUTRAL', 'UNRELATED'],\n",
       "      dtype='<U20')"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(results, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "c4cf24d7-ca26-4735-9a57-9cf826e0a286",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = []  \n",
    "  \n",
    "for word in results:  \n",
    "    lower_word = word.lower()  \n",
    "    if 'for' in lower_word:  \n",
    "        y_pred.append('agree')  \n",
    "    elif 'against' in lower_word:  \n",
    "        y_pred.append('disagree')  \n",
    "    elif 'comment' in lower_word or 'unrelated' in lower_word:  \n",
    "        y_pred.append('neutral')  \n",
    "    else:  \n",
    "        y_pred.append('neutral')\n",
    "        \n",
    "df['task_preds'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "e334043f-4a5f-4a40-813f-0021570ae054",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['agree', 'disagree', 'neutral'], dtype=object),\n",
       " array([ 4711,  9058, 18640]))"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df['task_preds'], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "371be09e-9f2b-47d1-bea2-7163fdb6015d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>stance</th>\n",
       "      <th>event</th>\n",
       "      <th>full_text</th>\n",
       "      <th>task_preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [tweet_id, stance, event, full_text, task_preds]\n",
       "Index: []"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['stance'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "906f54ca-301b-442e-9c0e-776598a98063",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       agree       0.21      0.23      0.22      4237\n",
      "    disagree       0.27      0.78      0.40      3170\n",
      "     neutral       0.81      0.60      0.69     25002\n",
      "\n",
      "    accuracy                           0.57     32409\n",
      "   macro avg       0.43      0.54      0.44     32409\n",
      "weighted avg       0.68      0.57      0.60     32409\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(df['stance'], df['task_preds'])\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753eac3e-fba1-4615-bc84-6b576814fd28",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3(b). Context prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "f23b18b6-82f8-4498-b9e1-5dbfb4662996",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# context prompt\n",
    "\n",
    "context_template = '''\n",
    "The following statement is a social media post that may be commenting on a corporate merger. Classify the statement as to whether it is 'FOR', 'AGAINST', 'NEUTRAL', or 'UNRELATED' to the event \"{event}\" happening. Only return the classification label for the statement, and no other text.\n",
    "\n",
    "statement: {statement}\n",
    "'''\n",
    "\n",
    "context_prompt = PromptTemplate(\n",
    "    input_variables=[\"event\",\"statement\"],\n",
    "    template=context_template\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76cda91-c949-4268-bfc8-39d3999eef46",
   "metadata": {},
   "source": [
    "### Run an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "17a0143a-cad6-45f7-845e-e90ed6dccd43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "event = df['event'][0]\n",
    "statements = df[df['event'] == event]['full_text'][0:20].tolist()\n",
    "y_true = df[df['event'] == event]['stance'][0:20].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "13ee5e07-ca7f-4ccc-98c3-29b230284adf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "llm_chain = LLMChain(prompt=context_prompt, llm=llm)\n",
    "\n",
    "results=[]\n",
    "for statement in statements:\n",
    "    results.append(llm_chain.run(event=event, statement=statement))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "88aefc12-a867-4975-9340-46ec79d49122",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       agree       0.00      0.00      0.00         3\n",
      "    disagree       0.00      0.00      0.00         0\n",
      "     neutral       0.75      0.53      0.62        17\n",
      "\n",
      "    accuracy                           0.45        20\n",
      "   macro avg       0.25      0.18      0.21        20\n",
      "weighted avg       0.64      0.45      0.53        20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# converting to given labels for comparison\n",
    "\n",
    "y_true = [str.lower(i) for i in y_true]\n",
    "y_pred = []  \n",
    "  \n",
    "for word in results:  \n",
    "    lower_word = word.lower()  \n",
    "    if 'for' in lower_word:  \n",
    "        y_pred.append('agree')  \n",
    "    elif 'against' in lower_word:  \n",
    "        y_pred.append('disagree')  \n",
    "    elif 'neutral' in lower_word or 'unrelated' in lower_word:  \n",
    "        y_pred.append('neutral')  \n",
    "    else:  \n",
    "        y_pred.append('neutral')\n",
    "\n",
    "# generating the classification report  \n",
    "report = classification_report(y_true, y_pred)  \n",
    "  \n",
    "print(report)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d122fe57-c6a0-4f9f-88f2-ab3b033d4969",
   "metadata": {},
   "source": [
    "### Run on all Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "20dbad2c-32b1-4d2d-a7be-ed3833768633",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "32409it [1:17:36,  6.96it/s]\n"
     ]
    }
   ],
   "source": [
    "# Running across the whole dataset\n",
    "\n",
    "results = []\n",
    "for index, row in tqdm(df.iterrows()):\n",
    "    results.append(llm_chain.run(event=row['event'], statement=row['full_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "f1733a30-6bd0-48c4-88ac-a9630c1464ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"'AGAINST'\", \"'FOR'\", \"'FOR' and 'AGAINST'.\", \"'NEUTRAL'\",\n",
       "       \"'UNRELATED'\", 'AGAINST', 'FOR', 'NEUTRAL', 'UNRELATED'],\n",
       "      dtype='<U20')"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(results, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "0da70805-b9b7-4840-9dbb-a31897733630",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = []  \n",
    "  \n",
    "for word in results:  \n",
    "    lower_word = word.lower()  \n",
    "    if 'for' in lower_word:  \n",
    "        y_pred.append('agree')  \n",
    "    elif 'against' in lower_word:  \n",
    "        y_pred.append('disagree')  \n",
    "    elif 'neutral' in lower_word or 'unrelated' in lower_word:  \n",
    "        y_pred.append('neutral')  \n",
    "    else:  \n",
    "        y_pred.append('neutral')\n",
    "        \n",
    "df['context_preds'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "4a9b196d-2158-40eb-9adb-84c62c5dcd53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['agree', 'disagree', 'neutral'], dtype=object),\n",
       " array([ 3231,  8978, 20200]))"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df['context_preds'], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e999ba12-0fa0-4204-bb0a-84376a5ab041",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       agree       0.28      0.21      0.24      4237\n",
      "    disagree       0.29      0.82      0.43      3170\n",
      "     neutral       0.82      0.66      0.73     25002\n",
      "\n",
      "    accuracy                           0.62     32409\n",
      "   macro avg       0.46      0.56      0.47     32409\n",
      "weighted avg       0.70      0.62      0.64     32409\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(df['stance'], df['context_preds'])\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a8755d-d895-49b1-bc13-1965215392fd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3(c). Context + FSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "0407c388-7977-443d-beba-03c0faa2ab64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create an example template\n",
    "\n",
    "example_template = '''\n",
    "event: {event}\n",
    "statement: {statement}\n",
    "stance: {stance}\n",
    "'''\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"event\",\"statement\", \"stance\"],\n",
    "    template=example_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "1cfae949-c846-4f0f-b31a-f84d30e54be9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Give some examples\n",
    "\n",
    "examples = [\n",
    "    {'event':\"Aetna buying Humana\",\n",
    "     'statement':'''Talk of Aetna, Anthem acquisition moves reaches fever pitch http://t.co/lxjHa7eXWh''',\n",
    "     'stance': 'NEUTRAL'},\n",
    "    {'event':\"Anthem buying Cigna\",\n",
    "     'statement':'''Sr. Mktg Advisor Aetna may acquire Humana or Cigna http://t.co/lTjwFi0Y8O #marketing #strategy''',\n",
    "     'stance': 'FOR'},\n",
    "    {'event':\"Cigna buying Express Scripts\",\n",
    "     'statement':'''Following the lead of CVS's $CVS acquisition of Aetna $AET and Cigna's $CI acquisition of Express Scripts Holding $ESRX, Walmart $WMT and Humana Inc $HUM are in preliminary talks focusing on possible partnership, or Walmart acquisition of Humana https://t.co/H2FWYwFJYz''',\n",
    "     'stance': 'NEUTRAL'},\n",
    "    {'event':\"CVS Health buying Aetna\",\n",
    "     'statement':'''@IngrahamAngle @realDonaldTrump He needs to block @cvshealth acquisition of @Aetna, and @Cigna acquisition of @ExpressScripts.  Patients will suffer.''',\n",
    "     'stance': 'AGAINST'},\n",
    "    {'event':\"Disney buying 21st Century Fox\",\n",
    "     'statement':'''Finally saw #Fant4stic \\nImmediately regretted it.''',\n",
    "     'stance': 'UNRELATED'},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "6ec3f4a3-be9d-46df-bed7-8b2afa937000",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prefix = \"\"\"\n",
    "The following statements are social media posts that may be commenting on a corporate merger. The statements can either be 'FOR', 'AGAINST', 'NEUTRAL', or 'UNRELATED' toward the corporate merger happening.\n",
    "\"\"\"\n",
    "\n",
    "suffix = '''\n",
    "Now, classify the following statement as to whether it is 'FOR', 'AGAINST','NEUTRAL', or 'UNRELATED' toward \"{event}\" happening. Only return the classification label for the statement, and no other text.\n",
    "\n",
    "statement: {statement}\n",
    "'''\n",
    "\n",
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"event\", \"statement\"],\n",
    "    example_separator=\"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6c9f10-3438-446e-9812-f4d1a1e70c1b",
   "metadata": {},
   "source": [
    "### Run an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "e66f40a8-3653-4ce5-be9c-aa64c49d28a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "event = df['event'][0]\n",
    "statements = df[df['event'] == event]['full_text'][0:20].tolist()\n",
    "y_true = df[df['event'] == event]['stance'][0:20].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "14e63860-b15e-4b0f-89be-16ef75f83c3e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "llm_chain = LLMChain(prompt=few_shot_prompt, llm=llm)\n",
    "\n",
    "results=[]\n",
    "for statement in statements:\n",
    "    results.append(llm_chain.run(event=event, statement=statement))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "48e8de6c-a692-4a13-a94a-a94ce0404006",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       agree       0.29      0.67      0.40         3\n",
      "    disagree       0.00      0.00      0.00         0\n",
      "     neutral       0.91      0.59      0.71        17\n",
      "\n",
      "    accuracy                           0.60        20\n",
      "   macro avg       0.40      0.42      0.37        20\n",
      "weighted avg       0.82      0.60      0.67        20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# converting to given labels for comparison\n",
    "\n",
    "y_true = [str.lower(i) for i in y_true]\n",
    "y_pred = []  \n",
    "  \n",
    "for word in results:  \n",
    "    lower_word = word.lower()  \n",
    "    if 'for' in lower_word:  \n",
    "        y_pred.append('agree')  \n",
    "    elif 'against' in lower_word:  \n",
    "        y_pred.append('disagree')  \n",
    "    elif 'neutral' in lower_word or 'unrelated' in lower_word:  \n",
    "        y_pred.append('neutral')  \n",
    "    else:  \n",
    "        y_pred.append('neutral')\n",
    "\n",
    "# generating the classification report  \n",
    "report = classification_report(y_true, y_pred)  \n",
    "  \n",
    "print(report)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0622d58d-9df3-4a17-8d22-244df05436de",
   "metadata": {},
   "source": [
    "### Run on all Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5169c2-4b07-4237-baf3-af889bdf11e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "18992it [1:09:45,  4.65it/s]"
     ]
    }
   ],
   "source": [
    "# Running across the whole dataset\n",
    "\n",
    "results = []\n",
    "for index, row in tqdm(df.iterrows()):\n",
    "    results.append(llm_chain.run(event=row['event'], statement=row['full_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d632a3-6a29-488d-b8f3-d895f6ffe05e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.unique(results, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc5c63a-b901-4541-81dd-e69985f36460",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = []  \n",
    "  \n",
    "for word in results:  \n",
    "    lower_word = word.lower()  \n",
    "    if 'for' in lower_word:  \n",
    "        y_pred.append('agree')  \n",
    "    elif 'against' in lower_word:  \n",
    "        y_pred.append('disagree')  \n",
    "    elif 'neutral' in lower_word or 'unrelated' in lower_word:  \n",
    "        y_pred.append('neutral')  \n",
    "    else:  \n",
    "        y_pred.append('neutral')\n",
    "        \n",
    "df['fsp_preds'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1521a68-6865-496e-87e1-5990887725a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.unique(df['fsp_preds'], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050cbe93-765c-4b30-bd7a-c8d293b99dff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "report = classification_report(df['stance'], df['fsp_preds'])\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b658afe0-4555-496c-b244-b00039433330",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3(d). Context + FSP + Reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940202db-ae18-42ca-9f75-2061b4281e44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create an example template\n",
    "\n",
    "example_and_reason_template = '''\n",
    "event: {event}\n",
    "statement: {statement}\n",
    "stance: {stance}\n",
    "reason: {reason}\n",
    "'''\n",
    "\n",
    "example_and_reason_prompt = PromptTemplate(\n",
    "    input_variables=[\"event\",\"statement\", \"stance\", \"reason\"],\n",
    "    template=example_and_reason_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e90a11-7697-4ee8-abd1-7dedbc3c0f47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Give some examples\n",
    "\n",
    "examples = [\n",
    "    {'event':\"Aetna buying Humana\",\n",
    "     'statement':'''Talk of Aetna, Anthem acquisition moves reaches fever pitch http://t.co/lxjHa7eXWh''',\n",
    "     'stance': 'NEUITRAL',\n",
    "     'reason': \"The statement is just a comment about the merger and so does not express a stance as for or against the merger.\"\n",
    "    },\n",
    "    {'event':\"Anthem buying Cigna\",\n",
    "     'statement':'''Sr. Mktg Advisor Aetna may acquire Humana or Cigna http://t.co/lTjwFi0Y8O #marketing #strategy''',\n",
    "     'stance': 'FOR',\n",
    "     'reason': 'The statement mentions that Aetna may acquire Cigna, which supports the merger happening.'\n",
    "    },\n",
    "    {'event':\"Cigna buying Express Scripts\",\n",
    "     'statement':'''Following the lead of CVS's $CVS acquisition of Aetna $AET and Cigna's $CI acquisition of Express Scripts Holding $ESRX, Walmart $WMT and Humana Inc $HUM are in preliminary talks focusing on possible partnership, or Walmart acquisition of Humana https://t.co/H2FWYwFJYz''',\n",
    "     'stance': 'NEUTRAL',\n",
    "     'reason': 'The statement mentions a number of possible mergers, and so is just a neutral comment on Cigna buying Express Scripts.'\n",
    "    },\n",
    "    {'event':\"CVS Health buying Aetna\",\n",
    "     'statement':'''@IngrahamAngle @realDonaldTrump He needs to block @cvshealth acquisition of @Aetna, and @Cigna acquisition of @ExpressScripts.  Patients will suffer.''',\n",
    "     'stance': 'AGAINST',\n",
    "     'reason': 'the statement is asking prominent political figures to block CVS Health buying Aetna over concerns for patients, thus the statement is against the merger.'\n",
    "    },\n",
    "    {'event':\"Disney buying 21st Century Fox\",\n",
    "     'statement':'''Finally saw #Fant4stic \\nImmediately regretted it.''',\n",
    "     'stance': 'UNRELATED',\n",
    "     'reason': 'The statement mentioned a Disney film but does not comment on Disney buying 21st Century Fox, so it is unrelated to the merger.'\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c0a06d-0604-445e-89b3-7807b6a60685",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prefix = \"\"\"\n",
    "The following statements are social media posts that may be commenting on a corporate merger. The statements can either be 'FOR', 'AGAINST', 'NEUTRAL', or 'UNRELATED' toward the corporate merger happening.\n",
    "\"\"\"\n",
    "\n",
    "suffix = '''\n",
    "Now, classify the following statement as to whether it is \"FOR\", \"AGAINST\", or \"NEUTRAL\" toward the \"{event}\" happening, and give your reasoning. Only return the classification label for the statement and the reason for the classification label in the form of: 'stance: STANCE, reason: REASON'\n",
    "\n",
    "statement: {statement}\n",
    "'''\n",
    "\n",
    "few_shot_and_reason_prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_and_reason_prompt,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"event\", \"statement\"],\n",
    "    example_separator=\"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13aabfb6-da64-4d33-b501-d24e5e0c41e8",
   "metadata": {},
   "source": [
    "### Run an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e71c23-d2eb-467c-8dfa-9b99521c0495",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "event = df['event'][0]\n",
    "statements = df[df['event'] == event]['full_text'][0:20].tolist()\n",
    "y_true = df[df['event'] == event]['stance'][0:20].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2606a6-dc35-45a4-aa4c-a9d0cdb733e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(prompt=few_shot_and_reason_prompt, llm=llm)\n",
    "\n",
    "results=[]\n",
    "for statement in statements:\n",
    "    results.append(llm_chain.run(event=event, statement=statement))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711e81c2-c074-4a35-8c93-a0b2575f8bb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = []  \n",
    "reasons = []  \n",
    "  \n",
    "for result in results:  \n",
    "    split_result = result.split('reason:')  \n",
    "    if len(split_result) == 2:  \n",
    "        # Extract stance and reason, remove leading/trailing whitespace and convert stance to lowercase  \n",
    "        stance, reason = split_result\n",
    "        stance = stance.replace('stance:', '').replace(',', '').strip().lower()\n",
    "        reason = reason.strip()\n",
    "        reasons.append(reason)\n",
    "    else:\n",
    "        # model did not give a reason\n",
    "        stance = split_result[0]\n",
    "        stance = stance.replace('stance:', '').replace(',', '').strip().lower()\n",
    "        reasons.append('')\n",
    "    if 'for' in stance:  \n",
    "        y_pred.append('agree')  \n",
    "    elif 'against' in stance:  \n",
    "        y_pred.append('disagree')  \n",
    "    elif 'neutral' in stance:\n",
    "        y_pred.append('neutral')  \n",
    "    else:  \n",
    "        y_pred.append('neutral')\n",
    "\n",
    "y_true = [str.lower(i) for i in y_true]\n",
    "\n",
    "# generating the classification report\n",
    "report = classification_report(y_true, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e47e691-8ef2-4cae-adf7-4e0211f04e5a",
   "metadata": {},
   "source": [
    "### Run on all Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d04c4ca-471d-46a1-896b-c26d61ba93e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Running across the whole dataset\n",
    "\n",
    "results = []\n",
    "for index, row in tqdm(df.iterrows()):\n",
    "    results.append(llm_chain.run(event=row['event'], statement=row['full_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97157b49-ef39-4c4d-9e1f-782eeafd3d9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = []  \n",
    "reasons = []  \n",
    "  \n",
    "for result in results:  \n",
    "    split_result = result.split('reason:')  \n",
    "    if len(split_result) == 2:  \n",
    "        # Extract stance and reason, remove leading/trailing whitespace and convert stance to lowercase  \n",
    "        stance, reason = split_result\n",
    "        stance = stance.replace('stance:', '').replace(',', '').strip().lower()\n",
    "        reason = reason.strip()\n",
    "        reasons.append(reason)\n",
    "    else:\n",
    "        # model did not give a reason\n",
    "        stance = split_result[0]\n",
    "        stance = stance.replace('stance:', '').replace(',', '').strip().lower()\n",
    "        reasons.append('')\n",
    "    if 'for' in stance:  \n",
    "        y_pred.append('agree')  \n",
    "    elif 'against' in stance:  \n",
    "        y_pred.append('disagree')  \n",
    "    elif 'neutral' in stance:  \n",
    "        y_pred.append('neutral')\n",
    "    else:  \n",
    "        y_pred.append('neutral')\n",
    "        \n",
    "df['fsp_reason_preds'] = y_pred\n",
    "df['fsp_reason_reasons'] = reasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02b73fb-2ec0-49f1-b0a2-baeef114f4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(df['fsp_reason_preds'], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44d2f6c-78b5-4740-9415-65c460ee3220",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "report = classification_report(df['stance'], df['fsp_reason_preds'])\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03aa11f-e001-4907-bd66-e989a653c0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"wtwt_flan-alpaca-3B_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94de7d2f-b6db-4714-8efe-f7cc1357b831",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
