{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b37c7bb-c037-4504-a2e2-4010b3726ac8",
   "metadata": {},
   "source": [
    "# Stance Classification for PhemeRumors\n",
    "- read in the data and pre-process\n",
    "- set up an LLM\n",
    "- Investigate different prompting schemes\n",
    "    - just context\n",
    "    - context + few-shot learning\n",
    "    - content + few-shot learning + reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b436af4-75ff-4598-a9e3-70e746e1f99d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.33.1-py3-none-any.whl (7.6 MB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.9.0)\n",
      "Collecting huggingface-hub<1.0,>=0.15.1 (from transformers)\n",
      "  Using cached huggingface_hub-0.17.1-py3-none-any.whl (294 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Using cached regex-2023.8.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (771 kB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.30.0)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
      "  Using cached tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "Collecting safetensors>=0.3.1 (from transformers)\n",
      "  Using cached safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n",
      "Installing collected packages: tokenizers, safetensors, regex, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.17.1 regex-2023.8.8 safetensors-0.3.3 tokenizers-0.13.3 transformers-4.33.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: langchain in /home/jovyan/.local/lib/python3.10/site-packages (0.0.158)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.13)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.4)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.2)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /home/jovyan/.local/lib/python3.10/site-packages (from langchain) (0.5.7)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.4)\n",
      "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
      "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /home/jovyan/.local/lib/python3.10/site-packages (from langchain) (1.2.4)\n",
      "Requirement already satisfied: pydantic<2,>=1 in /home/jovyan/.local/lib/python3.10/site-packages (from langchain) (1.10.8)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.30.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/jovyan/.local/lib/python3.10/site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: tqdm>=4.48.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.65.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /home/jovyan/.local/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.19.0)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /home/jovyan/.local/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (1.5.1)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in /home/jovyan/.local/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.8.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1->langchain) (4.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.5.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.3->langchain) (2.0.2)\n",
      "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Collecting accelerate\n",
      "  Using cached accelerate-0.22.0-py3-none-any.whl (251 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1+cu118)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.0.0)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (3.25.0)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (15.0.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Installing collected packages: accelerate\n",
      "Successfully installed accelerate-0.22.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Collecting einops\n",
      "  Using cached einops-0.6.1-py3-none-any.whl (42 kB)\n",
      "Installing collected packages: einops\n",
      "Successfully installed einops-0.6.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Collecting deepspeed\n",
      "  Using cached deepspeed-0.10.3-py3-none-any.whl\n",
      "Collecting hjson (from deepspeed)\n",
      "  Using cached hjson-3.1.0-py3-none-any.whl (54 kB)\n",
      "Collecting ninja (from deepspeed)\n",
      "  Using cached ninja-1.11.1-py2.py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (145 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deepspeed) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from deepspeed) (23.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from deepspeed) (5.9.5)\n",
      "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from deepspeed) (9.0.0)\n",
      "Requirement already satisfied: pydantic<2.0.0 in /home/jovyan/.local/lib/python3.10/site-packages (from deepspeed) (1.10.8)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from deepspeed) (2.0.1+cu118)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from deepspeed) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.0.0->deepspeed) (4.5.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (3.9.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (3.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (2.0.0)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->deepspeed) (3.25.0)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->deepspeed) (15.0.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->deepspeed) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->deepspeed) (1.3.0)\n",
      "Installing collected packages: ninja, hjson, deepspeed\n",
      "Successfully installed deepspeed-0.10.3 hjson-3.1.0 ninja-1.11.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Package installations to work on WIRE\n",
    "\n",
    "! pip install transformers\n",
    "! pip install langchain\n",
    "! pip install accelerate\n",
    "! pip install einops\n",
    "! pip install deepspeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86e77263-062c-44bc-8ace-6cf3a638e014",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-12 21:21:45.801333: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-12 21:21:46.547932: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-09-12 21:21:47,695] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "import os, re, pandas as pd, numpy as np, ast, json\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm  \n",
    "\n",
    "import torch\n",
    "from langchain import PromptTemplate, FewShotPromptTemplate, HuggingFacePipeline, LLMChain\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "import deepspeed\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5057d3-9986-42e2-91f9-ccb0a8a782e5",
   "metadata": {},
   "source": [
    "# 1. Import and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab8789ed-ab80-429d-a03e-6c07ac91a9d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file = os.path.join(\"phemerumours\",\"data_merged.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdaa0228-553d-4169-a510-a8a974955d6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e771931-ba00-487c-8c7a-dc68a435f86f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>stance</th>\n",
       "      <th>event</th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>576755174531862529</td>\n",
       "      <td>agree</td>\n",
       "      <td>putinmissing</td>\n",
       "      <td>Coup? RT @jimgeraghty: Rumors all Russian mili...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>576319832800555008</td>\n",
       "      <td>agree</td>\n",
       "      <td>putinmissing</td>\n",
       "      <td>Hoppla! @L0gg0l: Swiss Rumors: Putin absence d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>576513463738109954</td>\n",
       "      <td>disagree</td>\n",
       "      <td>putinmissing</td>\n",
       "      <td>Putin reappears on TV amid claims he is unwell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>552783667052167168</td>\n",
       "      <td>agree</td>\n",
       "      <td>charliehebdo</td>\n",
       "      <td>France: 10 people dead after shooting at HQ of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>552793679082311680</td>\n",
       "      <td>agree</td>\n",
       "      <td>charliehebdo</td>\n",
       "      <td>11 confirmed dead, Francois Hollande to visit ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id    stance         event   \n",
       "0  576755174531862529     agree  putinmissing  \\\n",
       "1  576319832800555008     agree  putinmissing   \n",
       "2  576513463738109954  disagree  putinmissing   \n",
       "3  552783667052167168     agree  charliehebdo   \n",
       "4  552793679082311680     agree  charliehebdo   \n",
       "\n",
       "                                           full_text  \n",
       "0  Coup? RT @jimgeraghty: Rumors all Russian mili...  \n",
       "1  Hoppla! @L0gg0l: Swiss Rumors: Putin absence d...  \n",
       "2  Putin reappears on TV amid claims he is unwell...  \n",
       "3  France: 10 people dead after shooting at HQ of...  \n",
       "4  11 confirmed dead, Francois Hollande to visit ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6ceb2cd-e7cc-4c58-aa8e-1b42f6f7e3ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2859, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8ce9d8c-8db7-4a90-bd5d-c5ada923046b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a dictionary with the original values as keys and new values as corresponding values  \n",
    "event_dict = {  \n",
    "    'putinmissing': \"Russian President Putin has gone missing\",   \n",
    "    'charliehebdo': \"there was a shooting event at Charlie Hebdo in Paris\",   \n",
    "    'prince-toronto': \"singer Prince will play a secret show in Toronto\",   \n",
    "    'ferguson': \"There is unrest in Ferguson, Missouri\",   \n",
    "    'germanwings-crash': \"A Germanwings plane crashed\",   \n",
    "    'ottawashooting': \"There was a shooting event in Ottawa\",   \n",
    "    'sydneysiege': \"There is a hostage situation in Sydney\",   \n",
    "    'ebola-essien': \"Michael Essien contracted Ebola\"  \n",
    "}  \n",
    "  \n",
    "# Use the map function to replace the values  \n",
    "df['event'] = df['event'].map(event_dict)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a182cfb3-9a8d-4e44-8570-eb37c9a418a0",
   "metadata": {},
   "source": [
    "# 2. Connect to LLM\n",
    "- for standing up a smaller huggingface model\n",
    "```python\n",
    "llm = HuggingFacePipeline.from_model_id(model_id=\"declare-lab/flan-alpaca-gpt4-xl\", task = 'text2text-generation', device=0,\n",
    "                                      model_kwargs={\"max_length\":500, \"do_sample\":False})\n",
    "```\n",
    "- for a mid-sized, more modern, huggingface model. You can use accelerate and chance ``` device = \"auto\"``` to use multiple GPUs\n",
    "```python\n",
    "model = \"tiiuae/falcon-7b-instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "    device_map=0,\n",
    "    max_length=200,\n",
    "    do_sample=False,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=pipe)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a845955d-162c-4531-a774-231a465372f6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38d4062c77054e6c8502e291fc17a0a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = \"google/flan-ul2\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\",\n",
    "    max_length=1000,\n",
    "    do_sample=False,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403fdd62-677d-467f-b0d6-ef232fc9ca70",
   "metadata": {},
   "source": [
    "look at a few examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "750d3b59-d13a-45ce-8f09-ee1680c395a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AGAINST'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = '''What is the stance of of the following social media post toward the U.S. Army. Give the stance as either 'FOR', \"AGAINST', or 'NEUTRAL'. Only return the stance:\n",
    "\"@vondeveen If the Army wants to actually recruit people, maybe stop breaking people and actually prosecute sexual assualt #nomorewar.\"\n",
    "'''\n",
    "llm(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8539ac1f-1155-4e53-9837-2f311a898965",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NEUTRAL'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = '''What is the stance of of the following social media post toward the U.S. Army. Give the stance as either 'FOR', \"AGAINST', or 'NEUTRAL'. Only return the stance:\n",
    "\"@artfulask I have never seen a pink-eared duck before. #Army\"\n",
    "'''\n",
    "llm(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "283a5080-d9f4-4e95-81be-da898da57990",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FOR'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = '''What is the stance of of the following social media post toward the U.S. Army. Give the stance as either 'FOR', \"AGAINST', or 'NEUTRAL'. Only return the stance:\n",
    "\"I think the @Army helped me become disciplined. I would have surely flunked out of college chasing tail if I didn't get some discipline there. #SFL\"\n",
    "'''\n",
    "llm(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c99f07-4c5d-49a7-bac9-36a3399c2927",
   "metadata": {},
   "source": [
    "# 3. Prompt Engineering for Stance Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e692217e-d8cb-44c8-ab54-21c3c076d6ee",
   "metadata": {},
   "source": [
    "## 3(a). Task-only prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5cefeed-4bcb-48a9-815f-7e02011e417a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# task-only prompt\n",
    "\n",
    "task_template = '''\n",
    "Classify the statement as to whether it \"SUPPORTS\", \"DENIES\", or is \"NEUTRAL\". Only return the classification label for the statement, and no other text.\n",
    "\n",
    "statement: {statement}\n",
    "'''\n",
    "\n",
    "task_prompt = PromptTemplate(\n",
    "    input_variables=[\"statement\"],\n",
    "    template=task_template\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0486f1e-b948-4cf8-921b-756139394b11",
   "metadata": {},
   "source": [
    "### Run an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a23f26eb-0ade-4a4e-9a99-5f91c9075438",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a sample for all examples\n",
    "\n",
    "random_sample_df = df.sample(50)\n",
    "y_true = random_sample_df['stance'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5a3a1f4-aac6-48be-8364-6e190ed49366",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "llm_chain = LLMChain(prompt=task_prompt, llm=llm)\n",
    "\n",
    "results=[]\n",
    "for row in random_sample_df.iterrows():\n",
    "    results.append(llm_chain.run(event=row[1]['event'], statement=row[1]['full_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e436eb7-c2f2-41cd-b484-cc9160c4b1f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       agree       0.00      0.00      0.00         4\n",
      "    disagree       0.00      0.00      0.00         0\n",
      "     neutral       0.90      0.80      0.85        46\n",
      "\n",
      "    accuracy                           0.74        50\n",
      "   macro avg       0.30      0.27      0.28        50\n",
      "weighted avg       0.83      0.74      0.78        50\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# converting to given labels for comparison\n",
    "\n",
    "y_true = [str.lower(i) for i in y_true]\n",
    "y_pred = [text.lower().replace('denies', 'disagree').replace('supports', 'agree').replace(\"neutrals\", \"neutral\") for text in results]\n",
    "\n",
    "# generating the classification report\n",
    "report = classification_report(y_true, y_pred)\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477aed9a-deec-40f1-85a3-fda877fb86c3",
   "metadata": {},
   "source": [
    "### Run on all Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2a3aa074-0261-4e3d-a57c-7313d9679bc4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "2859it [05:32,  8.61it/s]\n"
     ]
    }
   ],
   "source": [
    "# Running across the whole dataset\n",
    "\n",
    "results = []\n",
    "for index, row in tqdm(df.iterrows()):\n",
    "    results.append(llm_chain.run(event=row['event'], statement=row['full_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cfeeaebd-706c-47ca-b149-adf67d431630",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'DENIES', 'NEUTRAL', 'STRESS', 'SUPPORTS', 'Support',\n",
       "       'Supports',\n",
       "       'The statement \"I WILL KEEP THE BROWN FAMILY IN PRAYERS!\" is classified as \"SUPPORTS\".',\n",
       "       'The statement \"SUPPORTS\" the statement.', 'X'], dtype='<U85')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(results, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c4cf24d7-ca26-4735-9a57-9cf826e0a286",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_list = []  \n",
    "  \n",
    "for word in results:  \n",
    "    lower_word = word.lower()  \n",
    "    if 'support' in lower_word:  \n",
    "        output_list.append('agree')  \n",
    "    elif 'neg' in lower_word or 'denies' in lower_word:  \n",
    "        output_list.append('disagree')  \n",
    "    elif 'neutral' in lower_word:  \n",
    "        output_list.append('neutral')  \n",
    "    else:  \n",
    "        output_list.append('neutral')\n",
    "        \n",
    "df['task_preds'] = output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e334043f-4a5f-4a40-813f-0021570ae054",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['agree', 'disagree', 'neutral'], dtype=object),\n",
       " array([ 323,  532, 2004]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df['task_preds'], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "906f54ca-301b-442e-9c0e-776598a98063",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       agree       0.03      0.05      0.04       238\n",
      "    disagree       0.01      0.33      0.01         9\n",
      "     neutral       0.89      0.68      0.77      2612\n",
      "\n",
      "    accuracy                           0.63      2859\n",
      "   macro avg       0.31      0.35      0.27      2859\n",
      "weighted avg       0.81      0.63      0.71      2859\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(df['stance'], df['task_preds'])\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753eac3e-fba1-4615-bc84-6b576814fd28",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3(b). Context prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f23b18b6-82f8-4498-b9e1-5dbfb4662996",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# context prompt\n",
    "\n",
    "context_template = '''\n",
    "The following statement is a social media post commenting on whether a rumor is true. Classify the statement as to whether it \"SUPPORTS\", \"DENIES\", or is \"NEUTRAL\" toward the rumor below being true. Only return the classification label for the statement toward the rumor being true, and no other text.\n",
    "\n",
    "rumor: {event}\n",
    "statement: {statement}\n",
    "'''\n",
    "\n",
    "context_prompt = PromptTemplate(\n",
    "    input_variables=[\"event\",\"statement\"],\n",
    "    template=context_template\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76cda91-c949-4268-bfc8-39d3999eef46",
   "metadata": {},
   "source": [
    "### Run an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "13ee5e07-ca7f-4ccc-98c3-29b230284adf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "llm_chain = LLMChain(prompt=context_prompt, llm=llm)\n",
    "\n",
    "results=[]\n",
    "for row in random_sample_df.iterrows():\n",
    "    results.append(llm_chain.run(event=row[1]['event'], statement=row[1]['full_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "88aefc12-a867-4975-9340-46ec79d49122",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       agree       0.14      0.50      0.22         2\n",
      "    disagree       0.00      0.00      0.00         0\n",
      "     neutral       0.96      0.46      0.62        48\n",
      "\n",
      "    accuracy                           0.46        50\n",
      "   macro avg       0.37      0.32      0.28        50\n",
      "weighted avg       0.92      0.46      0.60        50\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# converting to given labels for comparison\n",
    "\n",
    "y_true = [str.lower(i) for i in y_true]\n",
    "y_pred = []  \n",
    "  \n",
    "for word in results:  \n",
    "    lower_word = word.lower()  \n",
    "    if 'support' in lower_word:  \n",
    "        y_pred.append('agree')  \n",
    "    elif 'neg' in lower_word or 'denies' in lower_word:  \n",
    "        y_pred.append('disagree')  \n",
    "    elif 'neutral' in lower_word:  \n",
    "        y_pred.append('neutral')  \n",
    "    else:  \n",
    "        y_pred.append('neutral')\n",
    "\n",
    "# generating the classification report  \n",
    "report = classification_report(y_true, y_pred)  \n",
    "  \n",
    "print(report)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d122fe57-c6a0-4f9f-88f2-ab3b033d4969",
   "metadata": {},
   "source": [
    "### Run on all Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "20dbad2c-32b1-4d2d-a7be-ed3833768633",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "2859it [06:02,  7.89it/s]\n"
     ]
    }
   ],
   "source": [
    "# Running across the whole dataset\n",
    "\n",
    "results = []\n",
    "for index, row in tqdm(df.iterrows()):\n",
    "    results.append(llm_chain.run(event=row['event'], statement=row['full_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "02874641-7878-416a-a9ed-b46b05a417b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'DENIES', 'MT', 'NEUTRAL', 'STRESS!', 'SUPPORTS', 'Supports',\n",
       "       'The statement \"SUPPORTS\" the rumor that Prince will play a secret show in Toronto.',\n",
       "       'The statement \"SUPPORTS\" the rumor that a Germanwings plane crashed.',\n",
       "       'The statement \"SUPPORTS\" the rumor that there is a hostage situation in Sydney.',\n",
       "       'The statement \"SUPPORTS\" the rumor that there was a shooting event at Charlie Hebdo in Paris.',\n",
       "       'The statement \"SUPPORTS\" the rumor that there was a shooting event in Ottawa.',\n",
       "       'X'], dtype='<U93')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(results, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0da70805-b9b7-4840-9dbb-a31897733630",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_list = []  \n",
    "  \n",
    "for word in results:  \n",
    "    lower_word = word.lower()  \n",
    "    if 'support' in lower_word:  \n",
    "        output_list.append('agree')  \n",
    "    elif 'neg' in lower_word or 'denies' in lower_word:  \n",
    "        output_list.append('disagree')  \n",
    "    elif 'neutral' in lower_word:  \n",
    "        output_list.append('neutral')  \n",
    "    else:  \n",
    "        output_list.append('neutral')\n",
    "        \n",
    "df['context_preds'] = output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4a9b196d-2158-40eb-9adb-84c62c5dcd53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['agree', 'disagree', 'neutral'], dtype=object),\n",
       " array([ 262,  254, 2343]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df['context_preds'], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e999ba12-0fa0-4204-bb0a-84376a5ab041",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       agree       0.23      0.25      0.24       238\n",
      "    disagree       0.01      0.33      0.02         9\n",
      "     neutral       0.93      0.83      0.88      2612\n",
      "\n",
      "    accuracy                           0.78      2859\n",
      "   macro avg       0.39      0.47      0.38      2859\n",
      "weighted avg       0.86      0.78      0.82      2859\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(df['stance'], df['context_preds'])\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a8755d-d895-49b1-bc13-1965215392fd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3(c). Context + FSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0407c388-7977-443d-beba-03c0faa2ab64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create an example template\n",
    "\n",
    "example_template = '''\n",
    "rumor: {rumor}\n",
    "statement: {statement}\n",
    "stance: {stance}\n",
    "'''\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"rumor\",\"statement\", \"stance\"],\n",
    "    template=example_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1cfae949-c846-4f0f-b31a-f84d30e54be9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Give some examples\n",
    "\n",
    "examples = [\n",
    "    {'rumor':\"Putin has gone missing\",\n",
    "     'statement':\"Putin reappears on TV amid claims he is unwell and under threat of coup http://t.co/YZln23EUx1 http://t.co/ZsAnBa5gz3\",\n",
    "     'stance': 'DENIES'},\n",
    "    {'rumor':\"Michael Essien contracted Ebola\",\n",
    "     'statement': '''What? \"@FootballcomEN: Unconfirmed reports claim that Michael Essien has contracted Ebola. http://t.co/GsEizhwaV7\"''',\n",
    "     'stance': 'NEUTRAL'},\n",
    "    {'rumor':\"A Germanwings plane crashed\",\n",
    "     'statement': '''@thatjohn @planefinder why would they say urgence in lieu of mayday which is standard ?''',\n",
    "     'stance': 'NEUTRAL'},\n",
    "    {'rumor':\"There is a hostage situation in Sydney\",\n",
    "     'statement': '''@KEEMSTARx dick head it's not confirmed its Jihadist extremists. Don't speculate''',\n",
    "     'stance': 'NEUTRAL'},\n",
    "    {'rumor':\"singer Prince will play a secret show in Toronto\",\n",
    "     'statement': '''OMG. #Prince rumoured to be performing in Toronto today. Exciting!''',\n",
    "     'stance': 'SUPPORTS'}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "88d60202-495d-4449-8dd6-3e984b03c0df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prefix = \"\"\"\n",
    "The following are social media posts commenting on whether a rumor is true. Each statement can either 'SUPPORT', be 'AGAINST', or be 'NEUTRAL' toward their associated rumor.\n",
    "\"\"\"\n",
    "\n",
    "suffix = '''\n",
    "Now, classify the following statement as to whether it \"SUPPORTS\", \"DENIES\", or is \"NEUTRAL\" toward the rumor below being true. Only return the classification label for the statement toward the rumor, and no other text.\n",
    "\n",
    "rumor: {event}\n",
    "statement: {statement}\n",
    "'''\n",
    "\n",
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"event\", \"statement\"],\n",
    "    example_separator=\"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6c9f10-3438-446e-9812-f4d1a1e70c1b",
   "metadata": {},
   "source": [
    "### Run an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "14e63860-b15e-4b0f-89be-16ef75f83c3e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "llm_chain = LLMChain(prompt=few_shot_prompt, llm=llm)\n",
    "\n",
    "results=[]\n",
    "for row in random_sample_df.iterrows():\n",
    "    results.append(llm_chain.run(event=row[1]['event'], statement=row[1]['full_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "48e8de6c-a692-4a13-a94a-a94ce0404006",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       agree       0.14      0.50      0.22         2\n",
      "    disagree       0.00      0.00      0.00         0\n",
      "     neutral       0.97      0.79      0.87        48\n",
      "\n",
      "    accuracy                           0.78        50\n",
      "   macro avg       0.37      0.43      0.37        50\n",
      "weighted avg       0.94      0.78      0.85        50\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# converting to given labels for comparison\n",
    "\n",
    "y_true = [str.lower(i) for i in y_true]\n",
    "y_pred = []  \n",
    "  \n",
    "for word in results:  \n",
    "    lower_word = word.lower()  \n",
    "    if 'support' in lower_word:  \n",
    "        y_pred.append('agree')  \n",
    "    elif 'denies' in lower_word:  \n",
    "        y_pred.append('disagree')  \n",
    "    elif 'neutral' in lower_word:  \n",
    "        y_pred.append('neutral')  \n",
    "    else:  \n",
    "        y_pred.append('neutral')\n",
    "\n",
    "# generating the classification report\n",
    "report = classification_report(y_true, y_pred)\n",
    "  \n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0622d58d-9df3-4a17-8d22-244df05436de",
   "metadata": {},
   "source": [
    "### Run on all Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bc5169c2-4b07-4237-baf3-af889bdf11e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "2859it [09:02,  5.27it/s]\n"
     ]
    }
   ],
   "source": [
    "# Running across the whole dataset\n",
    "\n",
    "results = []\n",
    "for index, row in tqdm(df.iterrows()):\n",
    "    results.append(llm_chain.run(event=row['event'], statement=row['full_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "105ac66a-2186-461e-b3dc-589eca1a1774",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([\"'AGAINST'\", \"'NEUTRAL'\", \"'SUPPORTS'\", 'AGAINST', 'DENIES',\n",
       "        'NEUTRAL', 'Support', 'Supports', 'X'], dtype='<U10'),\n",
       " array([ 275,    1,   67,   74,   45, 2256,   63,   76,    2]))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(results, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7dc5c63a-b901-4541-81dd-e69985f36460",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_list = []  \n",
    "  \n",
    "for word in results:  \n",
    "    lower_word = word.lower()  \n",
    "    if 'support' in lower_word:  \n",
    "        output_list.append('agree')  \n",
    "    elif 'denies' in lower_word:  \n",
    "        output_list.append('disagree')  \n",
    "    elif 'neutral' in lower_word:  \n",
    "        output_list.append('neutral')  \n",
    "    else:  \n",
    "        output_list.append('neutral')\n",
    "        \n",
    "df['fsp_preds'] = output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a1521a68-6865-496e-87e1-5990887725a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['agree', 'disagree', 'neutral'], dtype=object),\n",
       " array([ 206,   45, 2608]))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df['fsp_preds'], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "050cbe93-765c-4b30-bd7a-c8d293b99dff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       agree       0.21      0.18      0.20       238\n",
      "    disagree       0.04      0.22      0.07         9\n",
      "     neutral       0.92      0.92      0.92      2612\n",
      "\n",
      "    accuracy                           0.86      2859\n",
      "   macro avg       0.39      0.44      0.40      2859\n",
      "weighted avg       0.86      0.86      0.86      2859\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(df['stance'], df['fsp_preds'])\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b658afe0-4555-496c-b244-b00039433330",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3(d). Context + FSP + Reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "940202db-ae18-42ca-9f75-2061b4281e44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create an example template\n",
    "\n",
    "example_and_reason_template = '''\n",
    "rumor: {rumor}\n",
    "statement: {statement}\n",
    "stance: {stance}\n",
    "reason: {reason}\n",
    "'''\n",
    "\n",
    "example_and_reason_prompt = PromptTemplate(\n",
    "    input_variables=[\"rumor\",\"statement\", \"stance\", \"reason\"],\n",
    "    template=example_and_reason_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32e90a11-7697-4ee8-abd1-7dedbc3c0f47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Give some examples\n",
    "\n",
    "examples = [\n",
    "    {'rumor':\"Putin has gone missing\",\n",
    "     'statement':\"Putin reappears on TV amid claims he is unwell and under threat of coup http://t.co/YZln23EUx1 http://t.co/ZsAnBa5gz3\",\n",
    "     'stance': 'DENIES',\n",
    "     'reason': \"the statement denies that Putin has gone missing by saying he has reappeared on TV.\"\n",
    "    },\n",
    "    {'rumor':\"Michael Essien contracted Ebola\",\n",
    "     'statement': '''What? \"@FootballcomEN: Unconfirmed reports claim that Michael Essien has contracted Ebola. http://t.co/GsEizhwaV7\"''',\n",
    "     'stance': 'NEUTRAL',\n",
    "     'reason': \"the statement is neutral toward wether Michael Essen contracted Ebola, as it mostly just repeats the original post from @FootballcomEN while asking for more information.\"\n",
    "    },\n",
    "    {'rumor':\"A Germanwings plane crashed\",\n",
    "     'statement': '''@thatjohn @planefinder why would they say urgence in lieu of mayday which is standard ?''',\n",
    "     'stance': 'NEUTRAL',\n",
    "     'reason': \"the statement is neutral toward wether a germanwings plane crashed as it is only asking for clarifiying details about what has been reported.\"\n",
    "    },\n",
    "    {'rumor':\"There is a hostage situation in Sydney\",\n",
    "     'statement': '''@KEEMSTARx dick head it's not confirmed its Jihadist extremists. Don't speculate''',\n",
    "     'stance': 'NEUTRAL',\n",
    "     'reason': \"the statement is neutral toward wether there is a hostage siutation happening in Sydney as it is admonishing someone for speculating on a detail of the situation.\"\n",
    "    },\n",
    "    {'rumor':\"singer Prince will play a secret show in Toronto\",\n",
    "     'statement': '''OMG. #Prince rumoured to be performing in Toronto today. Exciting!''',\n",
    "     'stance': 'SUPPORTS',\n",
    "     'reason': 'The statement supports the rumor that the singer Prince performing a show in Toronto, as it expresses excitment at the singer performing.'\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58c0a06d-0604-445e-89b3-7807b6a60685",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prefix = \"\"\"\n",
    "The following are social media posts commenting on whether a rumor is true. Each statement can support, deny, or be neutral toward its associated rumor and Each statement has the reason for its stance toward the rumor.\n",
    "\"\"\"\n",
    "\n",
    "suffix = '''\n",
    "Now, classify the following statement as to whether it \"SUPPORTS\", \"DENIES\", or is \"NEUTRAL\" toward the rumor below being true, and give your reason for the classification. Only return the classification for the statement towards the rumor and the reasoning for the classification in the form of:'stance: STANCE, reason: REASON'\n",
    "\n",
    "rumor: {event}\n",
    "statement: {statement}\n",
    "'''\n",
    "\n",
    "few_shot_and_reason_prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_and_reason_prompt,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"event\", \"statement\"],\n",
    "    example_separator=\"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13aabfb6-da64-4d33-b501-d24e5e0c41e8",
   "metadata": {},
   "source": [
    "### Run an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2606a6-dc35-45a4-aa4c-a9d0cdb733e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "llm_chain = LLMChain(prompt=few_shot_and_reason_prompt, llm=llm)\n",
    "\n",
    "results=[]\n",
    "for row in random_sample_df.iterrows():\n",
    "    results.append(llm_chain.run(event=row[1]['event'], statement=row[1]['full_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711e81c2-c074-4a35-8c93-a0b2575f8bb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = []  \n",
    "reasons = []  \n",
    "  \n",
    "for result in results:  \n",
    "    split_result = result.split('reason:')  \n",
    "    if len(split_result) == 2:  \n",
    "        # Extract stance and reason, remove leading/trailing whitespace and convert stance to lowercase  \n",
    "        stance, reason = split_result\n",
    "        stance = stance.replace('stance:', '').replace(',', '').strip().lower()\n",
    "        reason = reason.strip()\n",
    "        reasons.append(reason)\n",
    "    else:\n",
    "        # model did not give a reason\n",
    "        stance = split_result[0]\n",
    "        stance = stance.replace('stance:', '').replace(',', '').strip().lower()\n",
    "        reasons.append('')\n",
    "    if 'for' in stance:  \n",
    "        y_pred.append('agree')  \n",
    "    elif 'against' in stance:  \n",
    "        y_pred.append('disagree')  \n",
    "    elif 'neutral' in stance:  \n",
    "        y_pred.append('neutral')\n",
    "    else:  \n",
    "        y_pred.append('neutral')\n",
    "\n",
    "y_true = [str.lower(i) for i in y_true]\n",
    "\n",
    "# generating the classification report\n",
    "report = classification_report(y_true, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e47e691-8ef2-4cae-adf7-4e0211f04e5a",
   "metadata": {},
   "source": [
    "### Run on all Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2d04c4ca-471d-46a1-896b-c26d61ba93e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "2859it [43:25,  1.10it/s]\n"
     ]
    }
   ],
   "source": [
    "# Running across the whole dataset\n",
    "\n",
    "results = []\n",
    "for index, row in tqdm(df.iterrows()):\n",
    "    results.append(llm_chain.run(event=row['event'], statement=row['full_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "97157b49-ef39-4c4d-9e1f-782eeafd3d9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = []  \n",
    "reasons = []  \n",
    "  \n",
    "for result in results:  \n",
    "    split_result = result.split('reason:')  \n",
    "    if len(split_result) == 2:  \n",
    "        # Extract stance and reason, remove leading/trailing whitespace and convert stance to lowercase  \n",
    "        stance, reason = split_result\n",
    "        stance = stance.replace('stance:', '').replace(',', '').strip().lower()\n",
    "        reason = reason.strip()\n",
    "        reasons.append(reason)\n",
    "    else:\n",
    "        # model did not give a reason\n",
    "        stance = split_result[0]\n",
    "        stance = stance.replace('stance:', '').replace(',', '').strip().lower()\n",
    "        reasons.append('')\n",
    "    if 'for' in stance:  \n",
    "        y_pred.append('agree')  \n",
    "    elif 'against' in stance:  \n",
    "        y_pred.append('disagree')  \n",
    "    elif 'neutral' in stance:  \n",
    "        y_pred.append('neutral')\n",
    "    else:  \n",
    "        y_pred.append('neutral')\n",
    "        \n",
    "df['fsp_reason_preds'] = y_pred\n",
    "df['fsp_reason_reasons'] = reasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b02b73fb-2ec0-49f1-b0a2-baeef114f4cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['neutral'], dtype=object), array([2859]))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df['fsp_reason_preds'], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e44d2f6c-78b5-4740-9415-65c460ee3220",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       agree       0.00      0.00      0.00       238\n",
      "    disagree       0.00      0.00      0.00         9\n",
      "     neutral       0.91      1.00      0.95      2612\n",
      "\n",
      "    accuracy                           0.91      2859\n",
      "   macro avg       0.30      0.33      0.32      2859\n",
      "weighted avg       0.83      0.91      0.87      2859\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(df['stance'], df['fsp_reason_preds'])\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d03aa11f-e001-4907-bd66-e989a653c0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"phemerumors_flan-alpaca-3B_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94de7d2f-b6db-4714-8efe-f7cc1357b831",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
